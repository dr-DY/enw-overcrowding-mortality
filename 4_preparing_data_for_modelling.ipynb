{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515c98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.preprocessing_for_modelling_functions import (\n",
    "    analyze_prison_deaths_and_overcrowding,\n",
    "    create_prison_dataset,\n",
    "    update_prison_dataframe,\n",
    "    add_highest_category_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86e5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized death types: ['Natural Causes' 'Self-Inflicted' 'Other' 'Homicide']\n",
      "WARNING: Some prison-month combinations have multiple rows\n",
      "     Prison Name  Year  Month  count\n",
      "7684        Hill  2013      3      2\n",
      "7685        Hill  2013      4      2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Denis\\Desktop\\EnW_mortality_github\\functions\\preprocessing_for_modelling_functions.py:136: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  summary = merged_df.groupby('Overcrowding_Status').agg(\n"
     ]
    }
   ],
   "source": [
    "merged_data_df, summary, death_types = analyze_prison_deaths_and_overcrowding(\n",
    "    'Output/Monthly_reports_processed/combined_prison_data.csv', \n",
    "    'Data/deaths_in_custody_by_prison.xlsx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f569bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 18586 rows\n",
      "Filtered dataset size: 14095 rows\n",
      "Removed 4491 rows\n",
      "\n",
      "First few rows of rearranged and filtered dataframe:\n",
      "        Prison Name Report_Date  Baseline CNA  In Use CNA  \\\n",
      "4131      Altcourse  2014-10-31           794       794.0   \n",
      "4132       Ashfield  2014-10-31           408       408.0   \n",
      "4133  Askham Grange  2014-10-31           150       126.0   \n",
      "4134      Aylesbury  2014-10-31           410       410.0   \n",
      "4135        Bedford  2014-10-31           322       322.0   \n",
      "\n",
      "      Operational Capacity  Population *  Year  Month  Occupancy_Percentage  \\\n",
      "4131                1133.0        1127.0  2014     10            141.939547   \n",
      "4132                 400.0         391.0  2014     10             95.833333   \n",
      "4133                 128.0         103.0  2014     10             81.746032   \n",
      "4134                 444.0         427.0  2014     10            104.146341   \n",
      "4135                 511.0         500.0  2014     10            155.279503   \n",
      "\n",
      "        Overcrowding_Status  Homicide  Natural Causes  Other  Self-Inflicted  \\\n",
      "4131    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "4132  At Capacity (90-100%)       0.0             0.0    0.0             0.0   \n",
      "4133  Below Capacity (<90%)       0.0             0.0    0.0             0.0   \n",
      "4134    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "4135    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "\n",
      "      Total_Deaths  \n",
      "4131           0.0  \n",
      "4132           0.0  \n",
      "4133           0.0  \n",
      "4134           0.0  \n",
      "4135           0.0  \n",
      "\n",
      "Minimum and Maximum values for each numerical column:\n",
      "                      Minimum  Maximum\n",
      "Baseline CNA             20.0   2106.0\n",
      "In Use CNA                0.0   2106.0\n",
      "Operational Capacity      0.0   2134.0\n",
      "Population *              0.0   2126.0\n",
      "Year                   2014.0   2024.0\n",
      "Month                     1.0     12.0\n",
      "Occupancy_Percentage      0.0    538.0\n",
      "Homicide                  0.0      1.0\n",
      "Natural Causes            0.0      6.0\n",
      "Other                     0.0      3.0\n",
      "Self-Inflicted            0.0      3.0\n",
      "Total_Deaths              0.0      6.0\n",
      "\n",
      "Date range information:\n",
      "Earliest report date: 2014-10-31 00:00:00\n",
      "Latest report date: 2024-09-30 00:00:00\n",
      "Total number of unique dates: 119\n",
      "\n",
      "Summary statistics for key columns:\n",
      "       Baseline CNA    In Use CNA  Operational Capacity  Population *  \\\n",
      "count  14095.000000  14093.000000          14093.000000  14062.000000   \n",
      "mean     671.265768    643.696019            736.303555    704.302162   \n",
      "std      319.798053    321.064771            372.955762    369.154053   \n",
      "min       20.000000      0.000000              0.000000      0.000000   \n",
      "25%      429.000000    409.000000            464.000000    443.000000   \n",
      "50%      610.000000    594.000000            663.000000    637.000000   \n",
      "75%      894.000000    854.000000           1013.000000    980.000000   \n",
      "max     2106.000000   2106.000000           2134.000000   2126.000000   \n",
      "\n",
      "       Occupancy_Percentage  \n",
      "count          13992.000000  \n",
      "mean             108.600381  \n",
      "std               22.375278  \n",
      "min                0.000000  \n",
      "25%               97.002809  \n",
      "50%              103.153218  \n",
      "75%              117.077963  \n",
      "max              538.000000  \n",
      "\n",
      "Count of different overcrowding statuses:\n",
      "Overcrowding_Status\n",
      "Overcrowded (>100%)      8208\n",
      "At Capacity (90-100%)    4174\n",
      "Below Capacity (<90%)    1606\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in each column:\n",
      "Prison Name               0\n",
      "Report_Date               0\n",
      "Baseline CNA              0\n",
      "In Use CNA                2\n",
      "Operational Capacity      2\n",
      "Population *             33\n",
      "Year                      0\n",
      "Month                     0\n",
      "Occupancy_Percentage    103\n",
      "Overcrowding_Status     107\n",
      "Homicide                  0\n",
      "Natural Causes            0\n",
      "Other                     0\n",
      "Self-Inflicted            0\n",
      "Total_Deaths              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming merged_data_df is already defined\n",
    "# If working with a file, you would load it first with:\n",
    "# merged_data_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# First, ensure Report_Date is in datetime format\n",
    "merged_data_df['Report_Date'] = pd.to_datetime(merged_data_df['Report_Date'])\n",
    "\n",
    "# Filter to only include data from October 2014 to September 2024\n",
    "start_date = pd.to_datetime('2014-10-01')\n",
    "end_date = pd.to_datetime('2024-09-30')\n",
    "\n",
    "filtered_df = merged_data_df[(merged_data_df['Report_Date'] >= start_date) & \n",
    "                            (merged_data_df['Report_Date'] <= end_date)]\n",
    "\n",
    "print(f\"Original dataset size: {len(merged_data_df)} rows\")\n",
    "print(f\"Filtered dataset size: {len(filtered_df)} rows\")\n",
    "print(f\"Removed {len(merged_data_df) - len(filtered_df)} rows\")\n",
    "\n",
    "# Rearrange columns in the specified order\n",
    "rearranged_columns = [\n",
    "    'Prison Name', \n",
    "    'Report_Date', \n",
    "    'Baseline CNA', \n",
    "    'In Use CNA', \n",
    "    'Operational Capacity',\n",
    "    'Population *', \n",
    "    'Year', \n",
    "    'Month', \n",
    "    'Occupancy_Percentage', \n",
    "    'Overcrowding_Status',\n",
    "    'Homicide', \n",
    "    'Natural Causes', \n",
    "    'Other', \n",
    "    'Self-Inflicted', \n",
    "    'Total_Deaths'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with rearranged columns and filtered dates\n",
    "rearranged_df = filtered_df[rearranged_columns]\n",
    "\n",
    "# Display the first few rows to verify the column order and date filtering\n",
    "print(\"\\nFirst few rows of rearranged and filtered dataframe:\")\n",
    "print(rearranged_df.head())\n",
    "\n",
    "# Examine the minimum and maximum values for each numerical column\n",
    "numeric_columns = rearranged_df.select_dtypes(include=[np.number]).columns\n",
    "min_max_df = pd.DataFrame({\n",
    "    'Minimum': rearranged_df[numeric_columns].min(),\n",
    "    'Maximum': rearranged_df[numeric_columns].max()\n",
    "})\n",
    "\n",
    "print(\"\\nMinimum and Maximum values for each numerical column:\")\n",
    "print(min_max_df)\n",
    "\n",
    "# Get additional information about the report dates\n",
    "print(\"\\nDate range information:\")\n",
    "print(f\"Earliest report date: {rearranged_df['Report_Date'].min()}\")\n",
    "print(f\"Latest report date: {rearranged_df['Report_Date'].max()}\")\n",
    "print(f\"Total number of unique dates: {rearranged_df['Report_Date'].nunique()}\")\n",
    "\n",
    "# Get summary statistics for key columns of interest\n",
    "columns_of_interest = ['Baseline CNA', 'In Use CNA', 'Operational Capacity', 'Population *', 'Occupancy_Percentage']\n",
    "print(\"\\nSummary statistics for key columns:\")\n",
    "print(rearranged_df[columns_of_interest].describe())\n",
    "\n",
    "# Count values in the Overcrowding_Status column\n",
    "print(\"\\nCount of different overcrowding statuses:\")\n",
    "print(rearranged_df['Overcrowding_Status'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(rearranged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab7e819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Operational Capacity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "In Use CNA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Prison Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Report_Date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Baseline CNA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Population *",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Year",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Occupancy_Percentage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Overcrowding_Status",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "Homicide",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Natural Causes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Other",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Self-Inflicted",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Total_Deaths",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f3ec6da6-0413-4c7f-8a95-744ca49baed4",
       "rows": [
        [
         "0",
         "1204.0",
         "794.0",
         "Altcourse",
         "2012-01-27 00:00:00",
         "794",
         "1147.0",
         "2012",
         "1",
         "144.45843828715365",
         "Overcrowded (>100%)",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "1",
         "383.0",
         "407.0",
         "Ashfield",
         "2012-01-27 00:00:00",
         "407",
         "313.0",
         "2012",
         "1",
         "76.90417690417691",
         "Below Capacity (<90%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "128.0",
         "126.0",
         "Askham Grange",
         "2012-01-27 00:00:00",
         "150",
         "122.0",
         "2012",
         "1",
         "96.82539682539682",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "444.0",
         "424.0",
         "Aylesbury",
         "2012-01-27 00:00:00",
         "436",
         "432.0",
         "2012",
         "1",
         "101.88679245283019",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "506.0",
         "322.0",
         "Bedford",
         "2012-01-27 00:00:00",
         "322",
         "502.0",
         "2012",
         "1",
         "155.90062111801242",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         "957.0",
         "800.0",
         "Belmarsh",
         "2012-01-27 00:00:00",
         "800",
         "892.0",
         "2012",
         "1",
         "111.5",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         "1450.0",
         "1093.0",
         "Birmingham",
         "2012-01-27 00:00:00",
         "1112",
         "1437.0",
         "2012",
         "1",
         "131.4730100640439",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         "122.0",
         "122.0",
         "Blantyre House",
         "2012-01-27 00:00:00",
         "122",
         "120.0",
         "2012",
         "1",
         "98.36065573770492",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "8",
         "466.0",
         "439.0",
         "Blundeston",
         "2012-01-27 00:00:00",
         "481",
         "461.0",
         "2012",
         "1",
         "105.01138952164008",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "9",
         "577.0",
         "545.0",
         "Brinsford",
         "2012-01-27 00:00:00",
         "545",
         "558.0",
         "2012",
         "1",
         "102.38532110091742",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         "648.0",
         "427.0",
         "Bristol",
         "2012-01-27 00:00:00",
         "427",
         "623.0",
         "2012",
         "1",
         "145.9016393442623",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "11",
         "798.0",
         "525.0",
         "Brixton",
         "2012-01-27 00:00:00",
         "530",
         "756.0",
         "2012",
         "1",
         "144.0",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "12",
         "527.0",
         "527.0",
         "Bronzefield",
         "2012-01-27 00:00:00",
         "527",
         "508.0",
         "2012",
         "1",
         "96.39468690702088",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "13",
         "445.0",
         "410.0",
         "Buckley Hall",
         "2012-01-27 00:00:00",
         "410",
         "440.0",
         "2012",
         "1",
         "107.31707317073172",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "14",
         "1114.0",
         "879.0",
         "Bullingdon",
         "2012-01-27 00:00:00",
         "879",
         "1091.0",
         "2012",
         "1",
         "124.11831626848692",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "15",
         "241.0",
         "220.0",
         "Bullwood Hall",
         "2012-01-27 00:00:00",
         "220",
         "239.0",
         "2012",
         "1",
         "108.63636363636364",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         "523.0",
         "503.0",
         "Bure",
         "2012-01-27 00:00:00",
         "503",
         "514.0",
         "2012",
         "1",
         "102.1868787276342",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "17",
         "314.0",
         "195.0",
         "Canterbury",
         "2012-01-27 00:00:00",
         "195",
         "300.0",
         "2012",
         "1",
         "153.84615384615387",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "18",
         "814.0",
         "539.0",
         "Cardiff",
         "2012-01-27 00:00:00",
         "554",
         "813.0",
         "2012",
         "1",
         "150.83487940630798",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         "751.0",
         "698.0",
         "Channings Wood",
         "2012-01-27 00:00:00",
         "698",
         "752.0",
         "2012",
         "1",
         "107.73638968481376",
         "Overcrowded (>100%)",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0"
        ],
        [
         "20",
         "752.0",
         "554.0",
         "Chelmsford",
         "2012-01-27 00:00:00",
         "554",
         "730.0",
         "2012",
         "1",
         "131.76895306859205",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         "513.0",
         "493.0",
         "Coldingley",
         "2012-01-27 00:00:00",
         "494",
         "510.0",
         "2012",
         "1",
         "103.44827586206897",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         "143.0",
         "143.0",
         "Cookham Wood",
         "2012-01-27 00:00:00",
         "143",
         "118.0",
         "2012",
         "1",
         "82.51748251748252",
         "Below Capacity (<90%)",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "23",
         "652.0",
         "635.0",
         "Dartmoor",
         "2012-01-27 00:00:00",
         "641",
         "630.0",
         "2012",
         "1",
         "99.21259842519686",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         "513.0",
         "513.0",
         "Deerbolt",
         "2012-01-27 00:00:00",
         "513",
         "477.0",
         "2012",
         "1",
         "92.98245614035088",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         "1145.0",
         "713.0",
         "Doncaster",
         "2012-01-27 00:00:00",
         "713",
         "1122.0",
         "2012",
         "1",
         "157.3632538569425",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "26",
         "271.0",
         "148.0",
         "Dorchester",
         "2012-01-27 00:00:00",
         "210",
         "242.0",
         "2012",
         "1",
         "163.51351351351352",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "27",
         "1135.0",
         "1060.0",
         "Dovegate",
         "2012-01-27 00:00:00",
         "1064",
         "1116.0",
         "2012",
         "1",
         "105.28301886792453",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "28",
         "357.0",
         "339.0",
         "Downview",
         "2012-01-27 00:00:00",
         "359",
         "314.0",
         "2012",
         "1",
         "92.62536873156341",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "29",
         "315.0",
         "315.0",
         "Drake Hall",
         "2012-01-27 00:00:00",
         "315",
         "298.0",
         "2012",
         "1",
         "94.6031746031746",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "30",
         "1017.0",
         "606.0",
         "Durham",
         "2012-01-27 00:00:00",
         "606",
         "916.0",
         "2012",
         "1",
         "151.15511551155117",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         "100.0",
         "98.0",
         "East Sutton Park",
         "2012-01-27 00:00:00",
         "98",
         "85.0",
         "2012",
         "1",
         "86.73469387755102",
         "Below Capacity (<90%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         "363.0",
         "333.0",
         "Eastwood Park",
         "2012-01-27 00:00:00",
         "333",
         "326.0",
         "2012",
         "1",
         "97.8978978978979",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "33",
         "1252.0",
         "943.0",
         "Elmley (Sheppey)",
         "2012-01-27 00:00:00",
         "943",
         "1182.0",
         "2012",
         "1",
         "125.34464475079534",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "1.0",
         "1.0"
        ],
        [
         "34",
         "689.0",
         "603.0",
         "Everthorpe",
         "2012-01-27 00:00:00",
         "603",
         "677.0",
         "2012",
         "1",
         "112.27197346600333",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "35",
         "550.0",
         "316.0",
         "Exeter",
         "2012-01-27 00:00:00",
         "325",
         "508.0",
         "2012",
         "1",
         "160.75949367088606",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "36",
         "687.0",
         "671.0",
         "Featherstone",
         "2012-01-27 00:00:00",
         "671",
         "683.0",
         "2012",
         "1",
         "101.78837555886737",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         "762.0",
         "762.0",
         "Feltham",
         "2012-01-27 00:00:00",
         "762",
         "709.0",
         "2012",
         "1",
         "93.04461942257218",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         "521.0",
         "521.0",
         "Ford",
         "2012-01-27 00:00:00",
         "521",
         "510.0",
         "2012",
         "1",
         "97.88867562380038",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "39",
         "1364.0",
         "1100.0",
         "Forest Bank",
         "2012-01-27 00:00:00",
         "1064",
         "1362.0",
         "2012",
         "1",
         "123.81818181818183",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         "310.0",
         "290.0",
         "Foston Hall",
         "2012-01-27 00:00:00",
         "290",
         "279.0",
         "2012",
         "1",
         "96.20689655172414",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "41",
         "844.0",
         "844.0",
         "Frankland",
         "2012-01-27 00:00:00",
         "859",
         "811.0",
         "2012",
         "1",
         "96.09004739336493",
         "At Capacity (90-100%)",
         "0.0",
         "2.0",
         "1.0",
         "1.0",
         "4.0"
        ],
        [
         "42",
         "608.0",
         "596.0",
         "Full Sutton",
         "2012-01-27 00:00:00",
         "604",
         "606.0",
         "2012",
         "1",
         "101.6778523489933",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "43",
         "846.0",
         "811.0",
         "Garth",
         "2012-01-27 00:00:00",
         "811",
         "836.0",
         "2012",
         "1",
         "103.0826140567201",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "44",
         "677.0",
         "677.0",
         "Gartree",
         "2012-01-27 00:00:00",
         "677",
         "673.0",
         "2012",
         "1",
         "99.40915805022156",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "45",
         "808.0",
         "649.0",
         "Glen Parva",
         "2012-01-27 00:00:00",
         "649",
         "765.0",
         "2012",
         "1",
         "117.87365177195686",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "46",
         "321.0",
         "213.0",
         "Gloucester",
         "2012-01-27 00:00:00",
         "221",
         "312.0",
         "2012",
         "1",
         "146.47887323943664",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "47",
         "238.0",
         "238.0",
         "Grendon",
         "2012-01-27 00:00:00",
         "251",
         "219.0",
         "2012",
         "1",
         "92.01680672268907",
         "At Capacity (90-100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "48",
         "509.0",
         "452.0",
         "Guys Marsh",
         "2012-01-27 00:00:00",
         "520",
         "489.0",
         "2012",
         "1",
         "108.1858407079646",
         "Overcrowded (>100%)",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "49",
         "266.0",
         "266.0",
         "Hatfield",
         "2012-01-27 00:00:00",
         "260",
         "259.0",
         "2012",
         "1",
         "97.36842105263158",
         "At Capacity (90-100%)",
         "0.0",
         "1.0",
         "0.0",
         "0.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 18586
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operational Capacity</th>\n",
       "      <th>In Use CNA</th>\n",
       "      <th>Prison Name</th>\n",
       "      <th>Report_Date</th>\n",
       "      <th>Baseline CNA</th>\n",
       "      <th>Population *</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Occupancy_Percentage</th>\n",
       "      <th>Overcrowding_Status</th>\n",
       "      <th>Homicide</th>\n",
       "      <th>Natural Causes</th>\n",
       "      <th>Other</th>\n",
       "      <th>Self-Inflicted</th>\n",
       "      <th>Total_Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1204.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>Altcourse</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>794</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>144.458438</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>Ashfield</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>407</td>\n",
       "      <td>313.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>76.904177</td>\n",
       "      <td>Below Capacity (&lt;90%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>Askham Grange</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>150</td>\n",
       "      <td>122.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>96.825397</td>\n",
       "      <td>At Capacity (90-100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>Aylesbury</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>436</td>\n",
       "      <td>432.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>101.886792</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>506.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>322</td>\n",
       "      <td>502.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>155.900621</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18581</th>\n",
       "      <td>458.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>Whitemoor</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>461</td>\n",
       "      <td>455.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>101.111111</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18582</th>\n",
       "      <td>646.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>Winchester</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>448</td>\n",
       "      <td>627.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>139.955357</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18583</th>\n",
       "      <td>586.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>Woodhill</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>647</td>\n",
       "      <td>548.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>139.440204</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18584</th>\n",
       "      <td>1274.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>Wormwood Scrubs</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>1183</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>104.770017</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18585</th>\n",
       "      <td>1192.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>Wymott</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>1192</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>110.393258</td>\n",
       "      <td>Overcrowded (&gt;100%)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18586 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Operational Capacity  In Use CNA      Prison Name Report_Date  \\\n",
       "0                    1204.0       794.0        Altcourse  2012-01-27   \n",
       "1                     383.0       407.0         Ashfield  2012-01-27   \n",
       "2                     128.0       126.0    Askham Grange  2012-01-27   \n",
       "3                     444.0       424.0        Aylesbury  2012-01-27   \n",
       "4                     506.0       322.0          Bedford  2012-01-27   \n",
       "...                     ...         ...              ...         ...   \n",
       "18581                 458.0       450.0        Whitemoor  2024-12-31   \n",
       "18582                 646.0       448.0       Winchester  2024-12-31   \n",
       "18583                 586.0       393.0         Woodhill  2024-12-31   \n",
       "18584                1274.0      1174.0  Wormwood Scrubs  2024-12-31   \n",
       "18585                1192.0      1068.0           Wymott  2024-12-31   \n",
       "\n",
       "       Baseline CNA  Population *  Year  Month  Occupancy_Percentage  \\\n",
       "0               794        1147.0  2012      1            144.458438   \n",
       "1               407         313.0  2012      1             76.904177   \n",
       "2               150         122.0  2012      1             96.825397   \n",
       "3               436         432.0  2012      1            101.886792   \n",
       "4               322         502.0  2012      1            155.900621   \n",
       "...             ...           ...   ...    ...                   ...   \n",
       "18581           461         455.0  2024     12            101.111111   \n",
       "18582           448         627.0  2024     12            139.955357   \n",
       "18583           647         548.0  2024     12            139.440204   \n",
       "18584          1183        1230.0  2024     12            104.770017   \n",
       "18585          1192        1179.0  2024     12            110.393258   \n",
       "\n",
       "         Overcrowding_Status  Homicide  Natural Causes  Other  Self-Inflicted  \\\n",
       "0        Overcrowded (>100%)       0.0             1.0    0.0             0.0   \n",
       "1      Below Capacity (<90%)       0.0             0.0    0.0             0.0   \n",
       "2      At Capacity (90-100%)       0.0             0.0    0.0             0.0   \n",
       "3        Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "4        Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "...                      ...       ...             ...    ...             ...   \n",
       "18581    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "18582    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "18583    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "18584    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "18585    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
       "\n",
       "       Total_Deaths  \n",
       "0               1.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "18581           0.0  \n",
       "18582           0.0  \n",
       "18583           0.0  \n",
       "18584           0.0  \n",
       "18585           0.0  \n",
       "\n",
       "[18586 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28ab712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results\n",
    "merged_data_df = rearranged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb49758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with 'Mount' before renaming: 23\n",
      "Number of entries with 'The Mount' before renaming: 96\n",
      "Number of entries with 'Mount' after renaming: 119\n",
      "Number of entries with 'The Mount' after renaming: 0\n",
      "\n",
      "Verify 'The Mount' is in the list of unique prison names:\n",
      "'The Mount' in unique prison names: False\n",
      "'Mount' in unique prison names: True\n",
      "\n",
      "Total number of unique prisons after renaming: 127\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_data_df is already defined\n",
    "# If working with a file, you would load it first with:\n",
    "# merged_data_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Print the count of 'Mount' entries before renaming\n",
    "mount_count_before = (merged_data_df['Prison Name'] == 'Mount').sum()\n",
    "print(f\"Number of entries with 'Mount' before renaming: {mount_count_before}\")\n",
    "\n",
    "# Check if 'The Mount' already exists and count occurrences\n",
    "the_mount_count_before = (merged_data_df['Prison Name'] == 'The Mount').sum()\n",
    "print(f\"Number of entries with 'The Mount' before renaming: {the_mount_count_before}\")\n",
    "\n",
    "# Rename 'Mount' to 'The Mount'\n",
    "merged_data_df['Prison Name'] = merged_data_df['Prison Name'].replace('The Mount', 'Mount')\n",
    "\n",
    "# Print the count after renaming to verify the change\n",
    "mount_count_after = (merged_data_df['Prison Name'] == 'Mount').sum()\n",
    "the_mount_count_after = (merged_data_df['Prison Name'] == 'The Mount').sum()\n",
    "\n",
    "print(f\"Number of entries with 'Mount' after renaming: {mount_count_after}\")\n",
    "print(f\"Number of entries with 'The Mount' after renaming: {the_mount_count_after}\")\n",
    "\n",
    "# Verify the unique prison names after the change\n",
    "print(\"\\nVerify 'The Mount' is in the list of unique prison names:\")\n",
    "unique_prisons = merged_data_df['Prison Name'].unique()\n",
    "print(\"'The Mount' in unique prison names:\", 'The Mount' in unique_prisons)\n",
    "print(\"'Mount' in unique prison names:\", 'Mount' in unique_prisons)\n",
    "\n",
    "# Optional: Show how many prisons are in the dataset after the change\n",
    "print(f\"\\nTotal number of unique prisons after renaming: {len(unique_prisons)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cfc02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- UPDATED DATASET INFORMATION ---\n",
      "Total number of prisons: 125\n",
      "Number of Category A prisons: 8\n",
      "Number of Category B prisons: 40\n",
      "Number of Category C prisons: 46\n",
      "Number of Category D prisons: 13\n",
      "Number of YOI prisons: 23\n",
      "Number of male prisons: 113\n",
      "Number of female prisons: 13\n",
      "Number of open female prisons: 2\n",
      "Number of closed female prisons: 12\n",
      "Number of mixed prisons: 1\n",
      "\n",
      "--- VERIFYING REMOVAL OF IRCs ---\n",
      "Haslar still in dataset: False\n",
      "Morton Hall still in dataset: False\n",
      "\n",
      "--- FINAL CHECKS ---\n",
      "All female prisons correctly marked as either open or closed (not both): True\n",
      "Percentage of male prisons with at least one valid category: 91.2%\n",
      "Number of dual-category sites: 3\n",
      "Dual-category prisons:\n",
      "  Grendon / Springhill: B+D\n",
      "  Moorland / Hatfield: C+D\n",
      "  Usk / Prescoed: C+D\n",
      "\n",
      "Number of Adult+YOI combined sites: 12\n",
      "Adult+YOI combined prisons:\n",
      "  Altcourse: B+YOI\n",
      "  Chelmsford: B+YOI\n",
      "  Doncaster: B+YOI\n",
      "  Durham: B+YOI\n",
      "  Exeter: B+YOI\n",
      "  Forest Bank: B+YOI\n",
      "  Hindley: C+YOI\n",
      "  Isis: C+YOI\n",
      "  Littlehey: C+YOI\n",
      "  Parc: B+YOI\n",
      "  Portland: C+YOI\n",
      "  Rochester: C+YOI\n",
      "\n",
      "--- VERIFYING SPECIFIC MULTI-CATEGORY SITES ---\n",
      "Grendon / Springhill: B=1, C=0, D=1, YOI=0\n",
      "Moorland / Hatfield: B=0, C=1, D=1, YOI=0\n",
      "Usk / Prescoed: B=0, C=1, D=1, YOI=0\n",
      "Littlehey: C=1, YOI=1\n",
      "Rochester: C=1, YOI=1\n",
      "Portland: C=1, YOI=1\n",
      "Parc: B=1, YOI=1\n",
      "Isis: C=1, YOI=1\n",
      "Hindley: C=1, YOI=1\n",
      "\n",
      "--- COLUMN ORDER CHECK ---\n",
      "Last column is 'Notes': True\n",
      "\n",
      "Dataset saved to 'Pre-processed_data/updated_prison_data_2014_2024.csv'\n"
     ]
    }
   ],
   "source": [
    "# This code assumes the previous script has been run and prison_df exists\n",
    "\n",
    "# Create the dataset\n",
    "prison_df = create_prison_dataset()\n",
    "\n",
    "# Apply the update function to the existing prison_df\n",
    "updated_prison_df = update_prison_dataframe(prison_df)\n",
    "\n",
    "# Display information about the updated dataset\n",
    "print(\"\\n--- UPDATED DATASET INFORMATION ---\")\n",
    "print(f\"Total number of prisons: {updated_prison_df['Prison_name'].nunique()}\")\n",
    "print(f\"Number of Category A prisons: {len(updated_prison_df[updated_prison_df['A'] == 1])}\")\n",
    "print(f\"Number of Category B prisons: {len(updated_prison_df[updated_prison_df['B'] == 1])}\")\n",
    "print(f\"Number of Category C prisons: {len(updated_prison_df[updated_prison_df['C'] == 1])}\")\n",
    "print(f\"Number of Category D prisons: {len(updated_prison_df[updated_prison_df['D'] == 1])}\")\n",
    "print(f\"Number of YOI prisons: {len(updated_prison_df[updated_prison_df['YOI'] == 1])}\")\n",
    "print(f\"Number of male prisons: {len(updated_prison_df[updated_prison_df['Male'] == 1])}\")\n",
    "print(f\"Number of female prisons: {len(updated_prison_df[updated_prison_df['Female'] == 1])}\")\n",
    "print(f\"Number of open female prisons: {len(updated_prison_df[updated_prison_df['Female_open'] == 1])}\")\n",
    "print(f\"Number of closed female prisons: {len(updated_prison_df[updated_prison_df['Female_closed'] == 1])}\")\n",
    "print(f\"Number of mixed prisons: {len(updated_prison_df[updated_prison_df['Mixed'] == 1])}\")\n",
    "\n",
    "# Verify that Haslar and Morton Hall have been removed\n",
    "print(\"\\n--- VERIFYING REMOVAL OF IRCs ---\")\n",
    "print(f\"Haslar still in dataset: {'Haslar' in updated_prison_df['Prison_name'].values}\")\n",
    "print(f\"Morton Hall still in dataset: {'Morton Hall' in updated_prison_df['Prison_name'].values}\")\n",
    "\n",
    "# Perform final checks on categorization\n",
    "print(\"\\n--- FINAL CHECKS ---\")\n",
    "\n",
    "# Check that all female prisons have correct open/closed designation\n",
    "female_prisons = updated_prison_df[updated_prison_df['Female'] == 1]\n",
    "valid_female = (female_prisons['Female_open'] + female_prisons['Female_closed'] == 1).all()\n",
    "print(f\"All female prisons correctly marked as either open or closed (not both): {valid_female}\")\n",
    "\n",
    "# Check that male prisons have valid category assignments\n",
    "male_prisons = updated_prison_df[(updated_prison_df['Male'] == 1) & (updated_prison_df['Female'] == 0)]\n",
    "valid_male_cats = ((male_prisons['A'] + male_prisons['B'] + male_prisons['C'] + male_prisons['D']).clip(upper=1) == 1).mean() * 100\n",
    "print(f\"Percentage of male prisons with at least one valid category: {valid_male_cats:.1f}%\")\n",
    "\n",
    "# Check dual-category sites\n",
    "dual_cats = updated_prison_df[(updated_prison_df['A'] + updated_prison_df['B'] + updated_prison_df['C'] + updated_prison_df['D']) > 1]\n",
    "print(f\"Number of dual-category sites: {len(dual_cats)}\")\n",
    "if len(dual_cats) > 0:\n",
    "    print(\"Dual-category prisons:\")\n",
    "    for _, row in dual_cats.iterrows():\n",
    "        cats = []\n",
    "        if row['A'] == 1: cats.append('A')\n",
    "        if row['B'] == 1: cats.append('B')\n",
    "        if row['C'] == 1: cats.append('C')\n",
    "        if row['D'] == 1: cats.append('D')\n",
    "        print(f\"  {row['Prison_name']}: {'+'.join(cats)}\")\n",
    "\n",
    "# Check Adult + YOI combined sites\n",
    "adult_yoi_sites = updated_prison_df[(updated_prison_df['YOI'] == 1) & (updated_prison_df['A'] + updated_prison_df['B'] + updated_prison_df['C'] + updated_prison_df['D'] >= 1)]\n",
    "print(f\"\\nNumber of Adult+YOI combined sites: {len(adult_yoi_sites)}\")\n",
    "if len(adult_yoi_sites) > 0:\n",
    "    print(\"Adult+YOI combined prisons:\")\n",
    "    for _, row in adult_yoi_sites.iterrows():\n",
    "        cats = []\n",
    "        if row['A'] == 1: cats.append('A')\n",
    "        if row['B'] == 1: cats.append('B')\n",
    "        if row['C'] == 1: cats.append('C')\n",
    "        if row['D'] == 1: cats.append('D')\n",
    "        print(f\"  {row['Prison_name']}: {'+'.join(cats)}+YOI\")\n",
    "\n",
    "# Verify specific multi-category sites\n",
    "print(\"\\n--- VERIFYING SPECIFIC MULTI-CATEGORY SITES ---\")\n",
    "for prison in ['Grendon / Springhill', 'Moorland / Hatfield', 'Usk / Prescoed']:\n",
    "    row = updated_prison_df[updated_prison_df['Prison_name'] == prison]\n",
    "    if not row.empty:\n",
    "        row = row.iloc[0]\n",
    "        print(f\"{prison}: B={row['B']}, C={row['C']}, D={row['D']}, YOI={row['YOI']}\")\n",
    "\n",
    "for prison in ['Littlehey', 'Rochester', 'Portland', 'Parc', 'Isis', 'Hindley']:\n",
    "    row = updated_prison_df[updated_prison_df['Prison_name'] == prison]\n",
    "    if not row.empty:\n",
    "        row = row.iloc[0]\n",
    "        if row['B'] == 1:\n",
    "            print(f\"{prison}: B={row['B']}, YOI={row['YOI']}\")\n",
    "        else:\n",
    "            print(f\"{prison}: C={row['C']}, YOI={row['YOI']}\")\n",
    "\n",
    "# Verify Notes column is at the end\n",
    "print(\"\\n--- COLUMN ORDER CHECK ---\")\n",
    "print(f\"Last column is 'Notes': {updated_prison_df.columns[-1] == 'Notes'}\")\n",
    "\n",
    "\n",
    "# Saving the output\n",
    "prison_df.to_csv('Output/Pre-processed_data/updated_prison_data_2014_2024.csv', index=False)\n",
    "prison_df.to_excel('Output/Pre-processed_data/updated_prison_data_2014_2024.xlsx', index=False)\n",
    "print(\"\\nDataset saved to 'Pre-processed_data/updated_prison_data_2014_2024.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b861008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL DATASET WITH HIGHEST CATEGORIES ---\n",
      "Total number of prisons: 125\n",
      "\n",
      "Distribution of Highest Male Categories:\n",
      "  C: 46\n",
      "  B: 40\n",
      "  Other: 13\n",
      "  YOI: 10\n",
      "  D: 10\n",
      "  A: 8\n",
      "\n",
      "Distribution of Highest Female Categories:\n",
      "  Other: 113\n",
      "  Closed: 12\n",
      "  Open: 2\n",
      "\n",
      "Mixed Prisons Categories:\n",
      "  Peterborough (Male & Female):\n",
      "    Male: B\n",
      "    Female: Closed\n",
      "\n",
      "Sample of Male Prisons with Highest Categories:\n",
      "  Lowdham Grange:\n",
      "    Original Categories: A=0, B=1, C=0, D=0, YOI=0\n",
      "    Highest Category: B\n",
      "  Swansea:\n",
      "    Original Categories: A=0, B=1, C=0, D=0, YOI=0\n",
      "    Highest Category: B\n",
      "  Brixton:\n",
      "    Original Categories: A=0, B=0, C=1, D=0, YOI=0\n",
      "    Highest Category: C\n",
      "  Channings Wood:\n",
      "    Original Categories: A=0, B=0, C=1, D=0, YOI=0\n",
      "    Highest Category: C\n",
      "  Liverpool:\n",
      "    Original Categories: A=0, B=1, C=0, D=0, YOI=0\n",
      "    Highest Category: B\n",
      "\n",
      "Sample of Female Prisons with Highest Categories:\n",
      "  East Sutton Park:\n",
      "    Original Categories: Female_open=1, Female_closed=0\n",
      "    Highest Category: Open\n",
      "  Holloway:\n",
      "    Original Categories: Female_open=0, Female_closed=1\n",
      "    Highest Category: Closed\n",
      "  Bronzefield:\n",
      "    Original Categories: Female_open=0, Female_closed=1\n",
      "    Highest Category: Closed\n",
      "  Send:\n",
      "    Original Categories: Female_open=0, Female_closed=1\n",
      "    Highest Category: Closed\n",
      "  Downview:\n",
      "    Original Categories: Female_open=0, Female_closed=1\n",
      "    Highest Category: Closed\n",
      "\n",
      "Dataset saved to 'Pre-processed_data/final_prison_data_2014_2024.csv'\n"
     ]
    }
   ],
   "source": [
    "# This code assumes the previous scripts have been run and updated_prison_df exists\n",
    "# It also assumes the add_highest_category_columns function has been defined\n",
    "\n",
    "# Apply the function to add highest category columns\n",
    "final_prison_df = add_highest_category_columns(updated_prison_df)\n",
    "\n",
    "# Display information about the final dataset\n",
    "print(\"\\n--- FINAL DATASET WITH HIGHEST CATEGORIES ---\")\n",
    "print(f\"Total number of prisons: {final_prison_df['Prison_name'].nunique()}\")\n",
    "\n",
    "# Show distribution of highest male categories\n",
    "print(\"\\nDistribution of Highest Male Categories:\")\n",
    "male_category_counts = final_prison_df['Highest_category_male'].value_counts()\n",
    "for category, count in male_category_counts.items():\n",
    "    print(f\"  {category}: {count}\")\n",
    "\n",
    "# Show distribution of highest female categories\n",
    "print(\"\\nDistribution of Highest Female Categories:\")\n",
    "female_category_counts = final_prison_df['Highest_category_female'].value_counts()\n",
    "for category, count in female_category_counts.items():\n",
    "    print(f\"  {category}: {count}\")\n",
    "\n",
    "# Check mixed prisons to ensure they have both male and female categories\n",
    "print(\"\\nMixed Prisons Categories:\")\n",
    "mixed_prisons = final_prison_df[final_prison_df['Mixed'] == 1]\n",
    "for _, row in mixed_prisons.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Male: {row['Highest_category_male']}\")\n",
    "    print(f\"    Female: {row['Highest_category_female']}\")\n",
    "\n",
    "# Sample of male prisons\n",
    "print(\"\\nSample of Male Prisons with Highest Categories:\")\n",
    "male_prisons = final_prison_df[(final_prison_df['Male'] == 1) & (final_prison_df['Female'] == 0)]\n",
    "sample_male = male_prisons.sample(min(5, len(male_prisons)))\n",
    "for _, row in sample_male.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Original Categories: A={row['A']}, B={row['B']}, C={row['C']}, D={row['D']}, YOI={row['YOI']}\")\n",
    "    print(f\"    Highest Category: {row['Highest_category_male']}\")\n",
    "\n",
    "# Sample of female prisons\n",
    "print(\"\\nSample of Female Prisons with Highest Categories:\")\n",
    "female_prisons = final_prison_df[(final_prison_df['Female'] == 1) & (final_prison_df['Male'] == 0)]\n",
    "sample_female = female_prisons.sample(min(5, len(female_prisons)))\n",
    "for _, row in sample_female.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Original Categories: Female_open={row['Female_open']}, Female_closed={row['Female_closed']}\")\n",
    "    print(f\"    Highest Category: {row['Highest_category_female']}\")\n",
    "\n",
    "\n",
    "# Saving the output\n",
    "prison_df.to_csv('Output/Pre-processed_data/final_prison_data_2014_2024.csv', index=False)\n",
    "prison_df.to_excel('Output/Pre-processed_data/final_prison_data_2014_2024.xlsx', index=False)\n",
    "print(\"\\nDataset saved to 'Pre-processed_data/final_prison_data_2014_2024.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bda8e6",
   "metadata": {},
   "source": [
    "## Integration of prison information toghether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c27d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prisons in first dataframe but not in second:\n",
      "- Haslar\n",
      "- Morton Hall\n",
      "\n",
      "Prisons in second dataframe but not in first:\n",
      "\n",
      "Checking for potential close matches (ignoring case and whitespace)...\n",
      "\n",
      "Potential similar names found:\n",
      "- 'moorland / hatfield' might match with: 'moorland', 'hatfield'\n",
      "- 'moorland' might match with: 'moorland / hatfield'\n",
      "- 'hatfield' might match with: 'moorland / hatfield'\n",
      "- 'northumberland' might match with: 'humber'\n",
      "- 'humber' might match with: 'northumberland'\n",
      "- 'standford hill (sheppey)' might match with: 'ford'\n",
      "- 'ford' might match with: 'chelmsford', 'standford hill (sheppey)', 'bedford', 'brinsford', 'stafford'\n",
      "- 'bedford' might match with: 'ford'\n",
      "- 'brinsford' might match with: 'ford'\n",
      "- 'chelmsford' might match with: 'ford'\n",
      "- 'stafford' might match with: 'ford'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's assume the first dataframe is called df1 and has 'Prison Name' column\n",
    "# and the second dataframe is called df2 and has 'Prison_name' column\n",
    "\n",
    "# Extract the unique prison names from both dataframes\n",
    "df1_prisons = set(merged_data_df['Prison Name'])\n",
    "df2_prisons = set(final_prison_df['Prison_name'])\n",
    "\n",
    "# Find prisons that are in df1 but not in df2\n",
    "only_in_df1 = df1_prisons - df2_prisons\n",
    "\n",
    "# Find prisons that are in df2 but not in df1\n",
    "only_in_df2 = df2_prisons - df1_prisons\n",
    "\n",
    "# Print the results\n",
    "print(\"Prisons in first dataframe but not in second:\")\n",
    "for prison in sorted(only_in_df1):\n",
    "    print(f\"- {prison}\")\n",
    "    \n",
    "print(\"\\nPrisons in second dataframe but not in first:\")\n",
    "for prison in sorted(only_in_df2):\n",
    "    print(f\"- {prison}\")\n",
    "\n",
    "# If there are no differences, print a confirmation\n",
    "if not only_in_df1 and not only_in_df2:\n",
    "    print(\"All prison names match across both dataframes.\")\n",
    "    \n",
    "# Sometimes string differences can be due to whitespace or capitalization\n",
    "# Let's check for potential close matches\n",
    "if only_in_df1 or only_in_df2:\n",
    "    print(\"\\nChecking for potential close matches (ignoring case and whitespace)...\")\n",
    "    \n",
    "    # Normalize names for comparison\n",
    "    df1_normalized = {p.lower().strip() for p in df1_prisons}\n",
    "    df2_normalized = {p.lower().strip() for p in df2_prisons}\n",
    "    \n",
    "    # Find potential matches\n",
    "    all_normalized = list(df1_normalized) + list(df2_normalized)\n",
    "    potential_matches = {}\n",
    "    \n",
    "    for i, name1 in enumerate(all_normalized):\n",
    "        for name2 in all_normalized[i+1:]:\n",
    "            if name1 == name2:\n",
    "                continue\n",
    "            # Check if one is a substring of the other\n",
    "            if name1 in name2 or name2 in name1:\n",
    "                potential_matches.setdefault(name1, set()).add(name2)\n",
    "                potential_matches.setdefault(name2, set()).add(name1)\n",
    "    \n",
    "    # Print potential matches\n",
    "    if potential_matches:\n",
    "        print(\"\\nPotential similar names found:\")\n",
    "        for name, matches in potential_matches.items():\n",
    "            if name in df1_normalized and any(m in df2_normalized for m in matches):\n",
    "                print(f\"- '{name}' might match with: {', '.join([f\"'{m}'\" for m in matches if m in df2_normalized])}\")\n",
    "            elif name in df2_normalized and any(m in df1_normalized for m in matches):\n",
    "                print(f\"- '{name}' might match with: {', '.join([f\"'{m}'\" for m in matches if m in df1_normalized])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "910d986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 14095 rows\n",
      "Filtered dataset size: 14043 rows\n",
      "Removed 52 rows\n",
      "\n",
      "Confirming prisons were removed:\n",
      "- Haslar was successfully removed\n",
      "- Morton Hall was successfully removed\n",
      "\n",
      "Sample of filtered dataset:\n",
      "        Prison Name Report_Date  Baseline CNA  In Use CNA  \\\n",
      "4131      Altcourse  2014-10-31           794       794.0   \n",
      "4132       Ashfield  2014-10-31           408       408.0   \n",
      "4133  Askham Grange  2014-10-31           150       126.0   \n",
      "4134      Aylesbury  2014-10-31           410       410.0   \n",
      "4135        Bedford  2014-10-31           322       322.0   \n",
      "\n",
      "      Operational Capacity  Population *  Year  Month  Occupancy_Percentage  \\\n",
      "4131                1133.0        1127.0  2014     10            141.939547   \n",
      "4132                 400.0         391.0  2014     10             95.833333   \n",
      "4133                 128.0         103.0  2014     10             81.746032   \n",
      "4134                 444.0         427.0  2014     10            104.146341   \n",
      "4135                 511.0         500.0  2014     10            155.279503   \n",
      "\n",
      "        Overcrowding_Status  Homicide  Natural Causes  Other  Self-Inflicted  \\\n",
      "4131    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "4132  At Capacity (90-100%)       0.0             0.0    0.0             0.0   \n",
      "4133  Below Capacity (<90%)       0.0             0.0    0.0             0.0   \n",
      "4134    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "4135    Overcrowded (>100%)       0.0             0.0    0.0             0.0   \n",
      "\n",
      "      Total_Deaths  \n",
      "4131           0.0  \n",
      "4132           0.0  \n",
      "4133           0.0  \n",
      "4134           0.0  \n",
      "4135           0.0  \n"
     ]
    }
   ],
   "source": [
    "df1 = merged_data_df\n",
    "\n",
    "# Assuming your first dataframe is called df1\n",
    "# Remove rows for Haslar and Morton Hall prisons\n",
    "prisons_to_remove = ['Haslar', 'Morton Hall']\n",
    "df1_filtered = df1[~df1['Prison Name'].isin(prisons_to_remove)]\n",
    "\n",
    "# Verify removal\n",
    "print(f\"Original dataset size: {len(df1)} rows\")\n",
    "print(f\"Filtered dataset size: {len(df1_filtered)} rows\")\n",
    "print(f\"Removed {len(df1) - len(df1_filtered)} rows\")\n",
    "\n",
    "# Check that the prisons were actually removed\n",
    "remaining_prisons = set(df1_filtered['Prison Name'])\n",
    "print(\"\\nConfirming prisons were removed:\")\n",
    "for prison in prisons_to_remove:\n",
    "    if prison in remaining_prisons:\n",
    "        print(f\"- Warning: {prison} is still in the dataset\")\n",
    "    else:\n",
    "        print(f\"- {prison} was successfully removed\")\n",
    "\n",
    "# Save the filtered dataset if needed\n",
    "# df1_filtered.to_csv('filtered_prison_data.csv', index=False)\n",
    "\n",
    "# Display sample of the filtered dataset\n",
    "print(\"\\nSample of filtered dataset:\")\n",
    "print(df1_filtered.head())\n",
    "\n",
    "merged_data = df1_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "842c099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original left dataframe size: 13782 rows\n",
      "Original right dataframe size: 127 rows\n",
      "Merged dataframe size: 13782 rows\n",
      "Rows dropped: 0 rows\n",
      "\n",
      "Merged data preview:\n",
      "     Prison Name Report_Date  Baseline CNA  In Use CNA  Operational Capacity  \\\n",
      "0      Altcourse  2014-10-31           794       794.0                1133.0   \n",
      "1       Ashfield  2014-10-31           408       408.0                 400.0   \n",
      "2  Askham Grange  2014-10-31           150       126.0                 128.0   \n",
      "3      Aylesbury  2014-10-31           410       410.0                 444.0   \n",
      "4        Bedford  2014-10-31           322       322.0                 511.0   \n",
      "\n",
      "   Population *  Year  Month  Occupancy_Percentage    Overcrowding_Status  \\\n",
      "0        1127.0  2014     10            141.939547    Overcrowded (>100%)   \n",
      "1         391.0  2014     10             95.833333  At Capacity (90-100%)   \n",
      "2         103.0  2014     10             81.746032  Below Capacity (<90%)   \n",
      "3         427.0  2014     10            104.146341    Overcrowded (>100%)   \n",
      "4         500.0  2014     10            155.279503    Overcrowded (>100%)   \n",
      "\n",
      "   ...  Male  Female  Mixed  Female_open  Female_closed  \\\n",
      "0  ...     1       0      0            0              0   \n",
      "1  ...     1       0      0            0              0   \n",
      "2  ...     0       1      0            1              0   \n",
      "3  ...     1       0      0            0              0   \n",
      "4  ...     1       0      0            0              0   \n",
      "\n",
      "                                               Notes Highest_category_male  \\\n",
      "0  Operated by G4S; houses adults and young offen...                     B   \n",
      "1  Operated by Serco; specializes in adult sex of...                     C   \n",
      "2         Open prison for adults and young offenders                 Other   \n",
      "3                         Young Offender Institution                   YOI   \n",
      "4                  Houses adults and young offenders                     B   \n",
      "\n",
      "   Highest_category_female  start_date   end_date  \n",
      "0                    Other  2014-10-01 2024-09-01  \n",
      "1                    Other  2014-10-01 2024-09-01  \n",
      "2                     Open  2014-10-01 2024-09-01  \n",
      "3                    Other  2014-10-01 2024-09-01  \n",
      "4                    Other  2014-10-01 2024-09-01  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming dataframes are named merged_data_df and final_prison_df\n",
    "# First, let's preprocess the date formats for comparison\n",
    "\n",
    "# Function to convert date strings to datetime objects\n",
    "def convert_period_to_date(period_str):\n",
    "    # Convert formats like \"10-2014\" to datetime objects\n",
    "    month, year = map(int, period_str.split('-'))\n",
    "    return datetime(year, month, 1)\n",
    "\n",
    "# Create datetime objects from Report_Date in merged_data\n",
    "merged_data_df['Report_Date'] = pd.to_datetime(merged_data_df['Report_Date'])\n",
    "\n",
    "# Create datetime objects from start_period and end_period in final_prison_df\n",
    "final_prison_df['start_date'] = final_prison_df['start_period'].apply(convert_period_to_date)\n",
    "final_prison_df['end_date'] = final_prison_df['end_period'].apply(convert_period_to_date)\n",
    "\n",
    "# Create a function to merge the datasets\n",
    "def merge_prison_data(left_df, right_df):\n",
    "    # Initialize an empty list to store matching rows\n",
    "    merged_rows = []\n",
    "    \n",
    "    # Iterate through each row in the left dataframe\n",
    "    for _, left_row in left_df.iterrows():\n",
    "        prison_name = left_row['Prison Name']\n",
    "        report_date = left_row['Report_Date']\n",
    "        \n",
    "        # Find matching prison names in the right dataframe\n",
    "        matching_prisons = right_df[right_df['Prison_name'] == prison_name]\n",
    "        \n",
    "        # Check if the report date falls within any of the matching prison's periods\n",
    "        for _, right_row in matching_prisons.iterrows():\n",
    "            if right_row['start_date'] <= report_date <= right_row['end_date']:\n",
    "                # Create a combined row with data from both dataframes\n",
    "                combined_row = pd.concat([left_row, right_row])\n",
    "                merged_rows.append(combined_row)\n",
    "                break  # Only take the first match per prison and date\n",
    "    \n",
    "    # Convert the list of rows into a dataframe\n",
    "    if merged_rows:\n",
    "        return pd.DataFrame(merged_rows)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Perform the merge\n",
    "result = merge_prison_data(merged_data_df, final_prison_df)\n",
    "\n",
    "# Clean up the result (remove duplicated columns if needed)\n",
    "# If 'Prison Name' and 'Prison_name' are duplicates, keep one\n",
    "if 'Prison Name' in result.columns and 'Prison_name' in result.columns:\n",
    "    result = result.drop(columns=['Prison_name'])\n",
    "\n",
    "# Print merge statistics\n",
    "print(f\"Original left dataframe size: {len(merged_data)} rows\")\n",
    "print(f\"Original right dataframe size: {len(final_prison_df)} rows\")\n",
    "print(f\"Merged dataframe size: {len(result)} rows\")\n",
    "print(f\"Rows dropped: {len(merged_data) - len(result)} rows\")\n",
    "\n",
    "# Display the first few rows of the merged result\n",
    "print(\"\\nMerged data preview:\")\n",
    "print(result.head())\n",
    "\n",
    "# Save the result\n",
    "result.to_csv('Output/Pre-processed_data/merged_prison_data_by_month.csv', index=False)\n",
    "result.to_excel('Output/Pre-processed_data/merged_prison_data_by_month.xlsx', index=False)\n",
    "\n",
    "result_copy = result.copy() #saving for later, for analysis needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34b912",
   "metadata": {},
   "source": [
    "## Aggregating data across a given period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03ec225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify period of interest\n",
    "start_date = pd.to_datetime('2014-10-01')\n",
    "end_date = pd.to_datetime('2024-09-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c64720b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Report_Date to datetime\n",
    "merged_data['Report_Date'] = pd.to_datetime(merged_data['Report_Date'])\n",
    "\n",
    "\n",
    "filtered_data = merged_data[(merged_data['Report_Date'] >= start_date) & \n",
    "                           (merged_data['Report_Date'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "470aa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the filtered data\n",
    "prison_agg = (\n",
    "    filtered_data\n",
    "    .groupby(\"Prison Name\")\n",
    "    .agg(\n",
    "        Avg_Population=(\"Population *\", \"mean\"),\n",
    "        Avg_Occupancy_Percentage=(\"Occupancy_Percentage\", \"mean\"),\n",
    "        Avg_Deaths=(\"Total_Deaths\", \"mean\"),\n",
    "        Avg_Homicide=(\"Homicide\", \"mean\"),\n",
    "        Avg_SelfInflicted=(\"Self-Inflicted\", \"mean\"),\n",
    "        Avg_Natural=(\"Natural Causes\", \"mean\"),\n",
    "        Avg_Other=(\"Other\", \"mean\"),\n",
    "        N_Months=(\"Total_Deaths\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71a97163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\Temp\\ipykernel_80704\\4021978012.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  result['end_period'] = pd.to_datetime(result['end_period'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean up the result dataframe column names\n",
    "result.columns = [col.replace('*', '').strip() for col in result.columns]\n",
    "\n",
    "# Convert end_period to datetime for sorting\n",
    "result['end_period'] = pd.to_datetime(result['end_period'], errors='coerce')\n",
    "\n",
    "# Sort the result dataframe by prison name and end_period\n",
    "result_sorted = result.sort_values(['Prison Name', 'end_period'])\n",
    "\n",
    "# Keep only the latest observation for each prison\n",
    "result_latest = result_sorted.drop_duplicates('Prison Name', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c766435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset has 123 prisons and 21 columns\n"
     ]
    }
   ],
   "source": [
    "# Merge the aggregated data with the latest prison information\n",
    "final_dataset = pd.merge(\n",
    "    prison_agg,\n",
    "    result_latest,\n",
    "    left_on=\"Prison Name\",\n",
    "    right_on=\"Prison Name\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "# Rename the column 'Prison Name' to 'Prison_name' in the final_dataset dataframe\n",
    "final_dataset.rename(columns={'Prison Name': 'Prison_name'}, inplace=True)\n",
    "\n",
    "\n",
    "# Keep only the columns we need\n",
    "keep_columns = [\n",
    "    'Prison_name',           # Prison identifier\n",
    "    'Avg_Population',        # Average metrics from merged_data\n",
    "    'Avg_Occupancy_Percentage',\n",
    "    'Avg_Deaths',\n",
    "    'Avg_Homicide',\n",
    "    'Avg_SelfInflicted',\n",
    "    'Avg_Natural',\n",
    "    'Avg_Other',\n",
    "    'N_Months',\n",
    "    'A', 'B', 'C', 'D',      # Prison type indicators\n",
    "    'YOI',\n",
    "    'Male', 'Female', \n",
    "    'Mixed',\n",
    "    'Female_open', \n",
    "    'Female_closed',\n",
    "    'Highest_category_male',\n",
    "    'Highest_category_female'\n",
    "]\n",
    "\n",
    "final_clean = final_dataset[keep_columns]\n",
    "\n",
    "# Display summary info\n",
    "print(f\"Final dataset has {final_clean.shape[0]} prisons and {final_clean.shape[1]} columns\")\n",
    "\n",
    "final_clean.to_excel('Output/Pre-processed_data/prison_agg_data_2014_2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c34ca",
   "metadata": {},
   "source": [
    "## Generate weighted aggregated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a8c7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted = merged_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eafc08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Drop rows with missing Overcrowding_Status\n",
    "df_weighted = df_weighted.dropna(subset=['Overcrowding_Status'])\n",
    "\n",
    "# Step 2: Create Month-Year column from Report_Date\n",
    "df_weighted['Report_Date'] = pd.to_datetime(df_weighted['Report_Date'])  # Ensure datetime dtype\n",
    "df_weighted['Month_Year'] = df_weighted['Report_Date'].dt.to_period('M')\n",
    "\n",
    "# Step 3: Flag COVID-period data\n",
    "df_weighted['Is_covid_acute'] = df_weighted['Report_Date'].between('2020-03-01', '2020-09-15').astype(int)\n",
    "df_weighted['Is_covid_residual'] = df_weighted['Report_Date'].between('2020-09-16', '2021-06-15').astype(int)\n",
    "df_weighted['Is_covid_ending'] = df_weighted['Report_Date'].between('2021-06-16', '2022-03-31').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330506d3",
   "metadata": {},
   "source": [
    "Estimating the effect of COVID-19 pandamic on excess mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "313e6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Denis\\miniconda3\\Lib\\site-packages\\statsmodels\\genmod\\cov_struct.py:796: FutureWarning: grid=True will become default in a future version\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               GEE Regression Results                              \n",
      "===================================================================================\n",
      "Dep. Variable:                Total_Deaths   No. Observations:                13760\n",
      "Model:                                 GEE   No. clusters:                      123\n",
      "Method:                        Generalized   Min. cluster size:                   3\n",
      "                      Estimating Equations   Max. cluster size:                 118\n",
      "Family:                            Poisson   Mean cluster size:               111.9\n",
      "Dependence structure:       Autoregressive   Num. iterations:                    20\n",
      "Date:                      ÐŸÐ½, 14 Ð°Ð¿Ñ€ 2025   Scale:                           1.000\n",
      "Covariance type:                    robust   Time:                         15:34:54\n",
      "=====================================================================================\n",
      "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "Intercept            -1.5457      0.076    -20.236      0.000      -1.695      -1.396\n",
      "Is_covid_acute        0.0188      0.078      0.240      0.810      -0.134       0.172\n",
      "Is_covid_residual     0.3031      0.070      4.360      0.000       0.167       0.439\n",
      "Is_covid_ending      -0.0323      0.066     -0.489      0.625      -0.162       0.097\n",
      "==============================================================================\n",
      "Skew:                          2.8565   Kurtosis:                      11.1863\n",
      "Centered skew:                 2.4377   Centered kurtosis:             10.1760\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.genmod.generalized_estimating_equations import GEE\n",
    "from statsmodels.genmod.families import Poisson\n",
    "from statsmodels.genmod.cov_struct import Autoregressive\n",
    "\n",
    "model = GEE.from_formula(\n",
    "    \"Total_Deaths ~ Is_covid_acute + Is_covid_residual + Is_covid_ending\",\n",
    "    groups=\"Prison Name\",\n",
    "    cov_struct=Autoregressive(),\n",
    "    family=Poisson(),\n",
    "    data=df_weighted\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b18811db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Report_Date  Months_Since  Time_Weight_Linear  Time_Weight_Exp\n",
      "0  2014-10-31           120                0.01         0.002479\n",
      "1  2014-10-31           120                0.01         0.002479\n",
      "2  2014-10-31           120                0.01         0.002479\n",
      "3  2014-10-31           120                0.01         0.002479\n",
      "4  2014-10-31           120                0.01         0.002479\n"
     ]
    }
   ],
   "source": [
    "# Creating weight columns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Make sure Report_Date is datetime\n",
    "df_weighted['Report_Date'] = pd.to_datetime(df_weighted['Report_Date'])\n",
    "\n",
    "# Reference point for weighting â€“ latest date in dataset (can be overridden)\n",
    "latest_date = df_weighted['Report_Date'].max()\n",
    "\n",
    "# Step 4: Compute recency in months (how far from the latest date)\n",
    "df_weighted['Months_Since'] = ((latest_date - df_weighted['Report_Date']) / pd.Timedelta(days=30)).round().astype(int)\n",
    "\n",
    "# Step 5: Define linear weight (more recent = higher weight)\n",
    "max_months = df_weighted['Months_Since'].max()\n",
    "df_weighted['Time_Weight_Linear'] = 1 - (df_weighted['Months_Since'] / max_months)\n",
    "\n",
    "# Optional: Clip to ensure non-negative\n",
    "df_weighted['Time_Weight_Linear'] = df_weighted['Time_Weight_Linear'].clip(lower=0.01)\n",
    "\n",
    "# ---- Optional: Exponential decay (steeper discount) ----\n",
    "decay_rate = 0.05  # change this value to control steepness\n",
    "df_weighted['Time_Weight_Exp'] = np.exp(-decay_rate * df_weighted['Months_Since'])\n",
    "\n",
    "# Preview\n",
    "print(df_weighted[['Report_Date', 'Months_Since', 'Time_Weight_Linear', 'Time_Weight_Exp']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8aa4f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Report_Date  Months_Since  Covid_Adjustment  Time_Weight_Linear  \\\n",
      "0  2014-10-31           120               1.0                0.01   \n",
      "1  2014-10-31           120               1.0                0.01   \n",
      "2  2014-10-31           120               1.0                0.01   \n",
      "3  2014-10-31           120               1.0                0.01   \n",
      "4  2014-10-31           120               1.0                0.01   \n",
      "\n",
      "   Time_Weight_Exp  Weight_Linear_Covid  Weight_Exp_Covid  \n",
      "0         0.002479                 0.01              0.01  \n",
      "1         0.002479                 0.01              0.01  \n",
      "2         0.002479                 0.01              0.01  \n",
      "3         0.002479                 0.01              0.01  \n",
      "4         0.002479                 0.01              0.01  \n"
     ]
    }
   ],
   "source": [
    "# Defining penalty multipliers for each COVID phase based on the results of the excess deaths estimation\n",
    "acute_penalty = 1          # Acute phase: 100% weight\n",
    "residual_penalty = 0.74      # Residual phase: 74% weight\n",
    "ending_penalty = 1         # Ending phase: 100% weight\n",
    "\n",
    "# Create COVID adjustment factor (weighted mask)\n",
    "df_weighted['Covid_Adjustment'] = (\n",
    "    df_weighted['Is_covid_acute'] * acute_penalty +\n",
    "    df_weighted['Is_covid_residual'] * residual_penalty +\n",
    "    df_weighted['Is_covid_ending'] * ending_penalty +\n",
    "    (~(\n",
    "        df_weighted['Is_covid_acute'].astype(bool) |\n",
    "        df_weighted['Is_covid_residual'].astype(bool) |\n",
    "        df_weighted['Is_covid_ending'].astype(bool)\n",
    "     )).astype(float) * 1.0  # non-COVID gets full weight\n",
    ")\n",
    "\n",
    "# Apply COVID adjustment to both weight types\n",
    "df_weighted['Weight_Linear_Covid'] = df_weighted['Time_Weight_Linear'] * df_weighted['Covid_Adjustment']\n",
    "df_weighted['Weight_Exp_Covid'] = df_weighted['Time_Weight_Exp'] * df_weighted['Covid_Adjustment']\n",
    "\n",
    "# Optional: prevent too-small weights\n",
    "df_weighted['Weight_Linear_Covid'] = df_weighted['Weight_Linear_Covid'].clip(lower=0.01)\n",
    "df_weighted['Weight_Exp_Covid'] = df_weighted['Weight_Exp_Covid'].clip(lower=0.01)\n",
    "\n",
    "# Preview\n",
    "print(df_weighted[['Report_Date', 'Months_Since', 'Covid_Adjustment',\n",
    "                   'Time_Weight_Linear', 'Time_Weight_Exp',\n",
    "                   'Weight_Linear_Covid', 'Weight_Exp_Covid']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcebe32",
   "metadata": {},
   "source": [
    "Adding weights based on prison population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32089d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Report_Date  Population  Months_Since  Covid_Adjustment  \\\n",
      "4578   2018-02-23       907.0            79               1.0   \n",
      "13542  2024-06-30       615.0             2               1.0   \n",
      "1999   2016-02-26       839.0           104               1.0   \n",
      "2643   2016-08-26      1163.0            98               1.0   \n",
      "103    2014-10-31       332.0           120               1.0   \n",
      "8161   2020-08-31       188.0            49               1.0   \n",
      "11395  2022-12-31      1066.0            20               1.0   \n",
      "3038   2016-11-25       776.0            95               1.0   \n",
      "7420   2020-02-28       941.0            55               1.0   \n",
      "4888   2018-04-30       665.0            77               1.0   \n",
      "\n",
      "       Time_Weight_Linear  Time_Weight_Exp  Weight_Linear_Covid  \\\n",
      "4578             0.341667         0.019255             0.341667   \n",
      "13542            0.983333         0.904837             0.983333   \n",
      "1999             0.133333         0.005517             0.133333   \n",
      "2643             0.183333         0.007447             0.183333   \n",
      "103              0.010000         0.002479             0.010000   \n",
      "8161             0.591667         0.086294             0.591667   \n",
      "11395            0.833333         0.367879             0.833333   \n",
      "3038             0.208333         0.008652             0.208333   \n",
      "7420             0.541667         0.063928             0.541667   \n",
      "4888             0.358333         0.021280             0.358333   \n",
      "\n",
      "       Weight_Exp_Covid  Weight_Linear_Covid_Pop  Weight_Exp_Covid_Pop  \n",
      "4578           0.019255               309.891667             17.464015  \n",
      "13542          0.904837               604.750000            556.475012  \n",
      "1999           0.010000               111.866667              8.390000  \n",
      "2643           0.010000               213.216667             11.630000  \n",
      "103            0.010000                 3.320000              3.320000  \n",
      "8161           0.086294               111.233333             16.223194  \n",
      "11395          0.367879               888.333333            392.159484  \n",
      "3038           0.010000               161.666667              7.760000  \n",
      "7420           0.063928               509.708333             60.156117  \n",
      "4888           0.021280               238.291667             14.151025  \n"
     ]
    }
   ],
   "source": [
    "# Sanity check: rename population column if needed\n",
    "df_weighted = df_weighted.rename(columns={'Population *': 'Population'})\n",
    "\n",
    "# --- Add weights with population adjustment ---\n",
    "df_weighted['Weight_Linear_Covid_Pop'] = df_weighted['Weight_Linear_Covid'] * df_weighted['Population']\n",
    "df_weighted['Weight_Exp_Covid_Pop'] = df_weighted['Weight_Exp_Covid'] * df_weighted['Population']\n",
    "\n",
    "# Optional: ensure no zero or negative weights (if population has zeros, though unlikely)\n",
    "df_weighted['Weight_Linear_Covid_Pop'] = df_weighted['Weight_Linear_Covid_Pop'].clip(lower=0.01)\n",
    "df_weighted['Weight_Exp_Covid_Pop'] = df_weighted['Weight_Exp_Covid_Pop'].clip(lower=0.01)\n",
    "\n",
    "# Show a random sample of 10 observations to inspect weight variability\n",
    "print(df_weighted[['Report_Date', 'Population', 'Months_Since', 'Covid_Adjustment',\n",
    "                   'Time_Weight_Linear', 'Time_Weight_Exp',\n",
    "                   'Weight_Linear_Covid', 'Weight_Exp_Covid',\n",
    "                   'Weight_Linear_Covid_Pop', 'Weight_Exp_Covid_Pop']].sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "49420855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the result\n",
    "df_weighted.to_excel('Output/For_analysis/merged_data_monthly_2014_2024_weighted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1f10a",
   "metadata": {},
   "source": [
    "# Prepare the folder for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "711ef33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING OUTLIERS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afadeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean.to_excel('Output/For_analysis/prison_agg_data_2014_2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c91b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset size: 13760 rows\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where Overcrowding_Status is empty\n",
    "result_copy = result_copy.dropna(subset=['Overcrowding_Status'])\n",
    "result_copy.rename(columns={'Prison Name': 'Prison_name', 'Population *': 'Population'}, inplace=True)\n",
    "\n",
    "\n",
    "# Verify the change\n",
    "print(f\"Updated dataset size: {len(result_copy)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7c611d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_copy.to_excel('Output/For_analysis/merged_data_monthly_2014_2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7075ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
