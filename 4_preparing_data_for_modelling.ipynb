{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515c98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.preprocessing_for_modelling_functions import (\n",
    "    analyze_prison_deaths_and_overcrowding,\n",
    "    create_prison_dataset,\n",
    "    update_prison_dataframe,\n",
    "    add_highest_category_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_df, summary, death_types = analyze_prison_deaths_and_overcrowding(\n",
    "    'Output/Monthly_reports_processed/combined_prison_data.csv', \n",
    "    'Data/deaths_in_custody_by_prison.xlsx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming merged_data_df is already defined\n",
    "# If working with a file, you would load it first with:\n",
    "# merged_data_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# First, ensure Report_Date is in datetime format\n",
    "merged_data_df['Report_Date'] = pd.to_datetime(merged_data_df['Report_Date'])\n",
    "\n",
    "# Filter to only include data from October 2014 to September 2024\n",
    "start_date = pd.to_datetime('2014-10-01')\n",
    "end_date = pd.to_datetime('2024-09-30')\n",
    "\n",
    "filtered_df = merged_data_df[(merged_data_df['Report_Date'] >= start_date) & \n",
    "                            (merged_data_df['Report_Date'] <= end_date)]\n",
    "\n",
    "print(f\"Original dataset size: {len(merged_data_df)} rows\")\n",
    "print(f\"Filtered dataset size: {len(filtered_df)} rows\")\n",
    "print(f\"Removed {len(merged_data_df) - len(filtered_df)} rows\")\n",
    "\n",
    "# Rearrange columns in the specified order\n",
    "rearranged_columns = [\n",
    "    'Prison Name', \n",
    "    'Report_Date', \n",
    "    'Baseline CNA', \n",
    "    'In Use CNA', \n",
    "    'Operational Capacity',\n",
    "    'Population *', \n",
    "    'Year', \n",
    "    'Month', \n",
    "    'Occupancy_Percentage', \n",
    "    'Overcrowding_Status',\n",
    "    'Homicide', \n",
    "    'Natural Causes', \n",
    "    'Other', \n",
    "    'Self-Inflicted', \n",
    "    'Total_Deaths'\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with rearranged columns and filtered dates\n",
    "rearranged_df = filtered_df[rearranged_columns]\n",
    "\n",
    "# Display the first few rows to verify the column order and date filtering\n",
    "print(\"\\nFirst few rows of rearranged and filtered dataframe:\")\n",
    "print(rearranged_df.head())\n",
    "\n",
    "# Examine the minimum and maximum values for each numerical column\n",
    "numeric_columns = rearranged_df.select_dtypes(include=[np.number]).columns\n",
    "min_max_df = pd.DataFrame({\n",
    "    'Minimum': rearranged_df[numeric_columns].min(),\n",
    "    'Maximum': rearranged_df[numeric_columns].max()\n",
    "})\n",
    "\n",
    "print(\"\\nMinimum and Maximum values for each numerical column:\")\n",
    "print(min_max_df)\n",
    "\n",
    "# Get additional information about the report dates\n",
    "print(\"\\nDate range information:\")\n",
    "print(f\"Earliest report date: {rearranged_df['Report_Date'].min()}\")\n",
    "print(f\"Latest report date: {rearranged_df['Report_Date'].max()}\")\n",
    "print(f\"Total number of unique dates: {rearranged_df['Report_Date'].nunique()}\")\n",
    "\n",
    "# Get summary statistics for key columns of interest\n",
    "columns_of_interest = ['Baseline CNA', 'In Use CNA', 'Operational Capacity', 'Population *', 'Occupancy_Percentage']\n",
    "print(\"\\nSummary statistics for key columns:\")\n",
    "print(rearranged_df[columns_of_interest].describe())\n",
    "\n",
    "# Count values in the Overcrowding_Status column\n",
    "print(\"\\nCount of different overcrowding statuses:\")\n",
    "print(rearranged_df['Overcrowding_Status'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(rearranged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ab712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results\n",
    "merged_data_df = rearranged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb49758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming merged_data_df is already defined\n",
    "# If working with a file, you would load it first with:\n",
    "# merged_data_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Print the count of 'Mount' entries before renaming\n",
    "mount_count_before = (merged_data_df['Prison Name'] == 'Mount').sum()\n",
    "print(f\"Number of entries with 'Mount' before renaming: {mount_count_before}\")\n",
    "\n",
    "# Check if 'The Mount' already exists and count occurrences\n",
    "the_mount_count_before = (merged_data_df['Prison Name'] == 'The Mount').sum()\n",
    "print(f\"Number of entries with 'The Mount' before renaming: {the_mount_count_before}\")\n",
    "\n",
    "# Rename 'Mount' to 'The Mount'\n",
    "merged_data_df['Prison Name'] = merged_data_df['Prison Name'].replace('The Mount', 'Mount')\n",
    "\n",
    "# Print the count after renaming to verify the change\n",
    "mount_count_after = (merged_data_df['Prison Name'] == 'Mount').sum()\n",
    "the_mount_count_after = (merged_data_df['Prison Name'] == 'The Mount').sum()\n",
    "\n",
    "print(f\"Number of entries with 'Mount' after renaming: {mount_count_after}\")\n",
    "print(f\"Number of entries with 'The Mount' after renaming: {the_mount_count_after}\")\n",
    "\n",
    "# Verify the unique prison names after the change\n",
    "print(\"\\nVerify 'The Mount' is in the list of unique prison names:\")\n",
    "unique_prisons = merged_data_df['Prison Name'].unique()\n",
    "print(\"'The Mount' in unique prison names:\", 'The Mount' in unique_prisons)\n",
    "print(\"'Mount' in unique prison names:\", 'Mount' in unique_prisons)\n",
    "\n",
    "# Optional: Show how many prisons are in the dataset after the change\n",
    "print(f\"\\nTotal number of unique prisons after renaming: {len(unique_prisons)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc02b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code assumes the previous script has been run and prison_df exists\n",
    "\n",
    "# Create the dataset\n",
    "prison_df = create_prison_dataset()\n",
    "\n",
    "# Apply the update function to the existing prison_df\n",
    "updated_prison_df = update_prison_dataframe(prison_df)\n",
    "\n",
    "# Display information about the updated dataset\n",
    "print(\"\\n--- UPDATED DATASET INFORMATION ---\")\n",
    "print(f\"Total number of prisons: {updated_prison_df['Prison_name'].nunique()}\")\n",
    "print(f\"Number of Category A prisons: {len(updated_prison_df[updated_prison_df['A'] == 1])}\")\n",
    "print(f\"Number of Category B prisons: {len(updated_prison_df[updated_prison_df['B'] == 1])}\")\n",
    "print(f\"Number of Category C prisons: {len(updated_prison_df[updated_prison_df['C'] == 1])}\")\n",
    "print(f\"Number of Category D prisons: {len(updated_prison_df[updated_prison_df['D'] == 1])}\")\n",
    "print(f\"Number of YOI prisons: {len(updated_prison_df[updated_prison_df['YOI'] == 1])}\")\n",
    "print(f\"Number of male prisons: {len(updated_prison_df[updated_prison_df['Male'] == 1])}\")\n",
    "print(f\"Number of female prisons: {len(updated_prison_df[updated_prison_df['Female'] == 1])}\")\n",
    "print(f\"Number of open female prisons: {len(updated_prison_df[updated_prison_df['Female_open'] == 1])}\")\n",
    "print(f\"Number of closed female prisons: {len(updated_prison_df[updated_prison_df['Female_closed'] == 1])}\")\n",
    "print(f\"Number of mixed prisons: {len(updated_prison_df[updated_prison_df['Mixed'] == 1])}\")\n",
    "\n",
    "# Verify that Haslar and Morton Hall have been removed\n",
    "print(\"\\n--- VERIFYING REMOVAL OF IRCs ---\")\n",
    "print(f\"Haslar still in dataset: {'Haslar' in updated_prison_df['Prison_name'].values}\")\n",
    "print(f\"Morton Hall still in dataset: {'Morton Hall' in updated_prison_df['Prison_name'].values}\")\n",
    "\n",
    "# Perform final checks on categorization\n",
    "print(\"\\n--- FINAL CHECKS ---\")\n",
    "\n",
    "# Check that all female prisons have correct open/closed designation\n",
    "female_prisons = updated_prison_df[updated_prison_df['Female'] == 1]\n",
    "valid_female = (female_prisons['Female_open'] + female_prisons['Female_closed'] == 1).all()\n",
    "print(f\"All female prisons correctly marked as either open or closed (not both): {valid_female}\")\n",
    "\n",
    "# Check that male prisons have valid category assignments\n",
    "male_prisons = updated_prison_df[(updated_prison_df['Male'] == 1) & (updated_prison_df['Female'] == 0)]\n",
    "valid_male_cats = ((male_prisons['A'] + male_prisons['B'] + male_prisons['C'] + male_prisons['D']).clip(upper=1) == 1).mean() * 100\n",
    "print(f\"Percentage of male prisons with at least one valid category: {valid_male_cats:.1f}%\")\n",
    "\n",
    "# Check dual-category sites\n",
    "dual_cats = updated_prison_df[(updated_prison_df['A'] + updated_prison_df['B'] + updated_prison_df['C'] + updated_prison_df['D']) > 1]\n",
    "print(f\"Number of dual-category sites: {len(dual_cats)}\")\n",
    "if len(dual_cats) > 0:\n",
    "    print(\"Dual-category prisons:\")\n",
    "    for _, row in dual_cats.iterrows():\n",
    "        cats = []\n",
    "        if row['A'] == 1: cats.append('A')\n",
    "        if row['B'] == 1: cats.append('B')\n",
    "        if row['C'] == 1: cats.append('C')\n",
    "        if row['D'] == 1: cats.append('D')\n",
    "        print(f\"  {row['Prison_name']}: {'+'.join(cats)}\")\n",
    "\n",
    "# Check Adult + YOI combined sites\n",
    "adult_yoi_sites = updated_prison_df[(updated_prison_df['YOI'] == 1) & (updated_prison_df['A'] + updated_prison_df['B'] + updated_prison_df['C'] + updated_prison_df['D'] >= 1)]\n",
    "print(f\"\\nNumber of Adult+YOI combined sites: {len(adult_yoi_sites)}\")\n",
    "if len(adult_yoi_sites) > 0:\n",
    "    print(\"Adult+YOI combined prisons:\")\n",
    "    for _, row in adult_yoi_sites.iterrows():\n",
    "        cats = []\n",
    "        if row['A'] == 1: cats.append('A')\n",
    "        if row['B'] == 1: cats.append('B')\n",
    "        if row['C'] == 1: cats.append('C')\n",
    "        if row['D'] == 1: cats.append('D')\n",
    "        print(f\"  {row['Prison_name']}: {'+'.join(cats)}+YOI\")\n",
    "\n",
    "# Verify specific multi-category sites\n",
    "print(\"\\n--- VERIFYING SPECIFIC MULTI-CATEGORY SITES ---\")\n",
    "for prison in ['Grendon / Springhill', 'Moorland / Hatfield', 'Usk / Prescoed']:\n",
    "    row = updated_prison_df[updated_prison_df['Prison_name'] == prison]\n",
    "    if not row.empty:\n",
    "        row = row.iloc[0]\n",
    "        print(f\"{prison}: B={row['B']}, C={row['C']}, D={row['D']}, YOI={row['YOI']}\")\n",
    "\n",
    "for prison in ['Littlehey', 'Rochester', 'Portland', 'Parc', 'Isis', 'Hindley']:\n",
    "    row = updated_prison_df[updated_prison_df['Prison_name'] == prison]\n",
    "    if not row.empty:\n",
    "        row = row.iloc[0]\n",
    "        if row['B'] == 1:\n",
    "            print(f\"{prison}: B={row['B']}, YOI={row['YOI']}\")\n",
    "        else:\n",
    "            print(f\"{prison}: C={row['C']}, YOI={row['YOI']}\")\n",
    "\n",
    "# Verify Notes column is at the end\n",
    "print(\"\\n--- COLUMN ORDER CHECK ---\")\n",
    "print(f\"Last column is 'Notes': {updated_prison_df.columns[-1] == 'Notes'}\")\n",
    "\n",
    "\n",
    "# Saving the output\n",
    "prison_df.to_csv('Output/Pre-processed_data/updated_prison_data_2014_2024.csv', index=False)\n",
    "prison_df.to_excel('Output/Pre-processed_data/updated_prison_data_2014_2024.xlsx', index=False)\n",
    "print(\"\\nDataset saved to 'Pre-processed_data/updated_prison_data_2014_2024.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b861008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code assumes the previous scripts have been run and updated_prison_df exists\n",
    "# It also assumes the add_highest_category_columns function has been defined\n",
    "\n",
    "# Apply the function to add highest category columns\n",
    "final_prison_df = add_highest_category_columns(updated_prison_df)\n",
    "\n",
    "# Display information about the final dataset\n",
    "print(\"\\n--- FINAL DATASET WITH HIGHEST CATEGORIES ---\")\n",
    "print(f\"Total number of prisons: {final_prison_df['Prison_name'].nunique()}\")\n",
    "\n",
    "# Show distribution of highest male categories\n",
    "print(\"\\nDistribution of Highest Male Categories:\")\n",
    "male_category_counts = final_prison_df['Highest_category_male'].value_counts()\n",
    "for category, count in male_category_counts.items():\n",
    "    print(f\"  {category}: {count}\")\n",
    "\n",
    "# Show distribution of highest female categories\n",
    "print(\"\\nDistribution of Highest Female Categories:\")\n",
    "female_category_counts = final_prison_df['Highest_category_female'].value_counts()\n",
    "for category, count in female_category_counts.items():\n",
    "    print(f\"  {category}: {count}\")\n",
    "\n",
    "# Check mixed prisons to ensure they have both male and female categories\n",
    "print(\"\\nMixed Prisons Categories:\")\n",
    "mixed_prisons = final_prison_df[final_prison_df['Mixed'] == 1]\n",
    "for _, row in mixed_prisons.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Male: {row['Highest_category_male']}\")\n",
    "    print(f\"    Female: {row['Highest_category_female']}\")\n",
    "\n",
    "# Sample of male prisons\n",
    "print(\"\\nSample of Male Prisons with Highest Categories:\")\n",
    "male_prisons = final_prison_df[(final_prison_df['Male'] == 1) & (final_prison_df['Female'] == 0)]\n",
    "sample_male = male_prisons.sample(min(5, len(male_prisons)))\n",
    "for _, row in sample_male.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Original Categories: A={row['A']}, B={row['B']}, C={row['C']}, D={row['D']}, YOI={row['YOI']}\")\n",
    "    print(f\"    Highest Category: {row['Highest_category_male']}\")\n",
    "\n",
    "# Sample of female prisons\n",
    "print(\"\\nSample of Female Prisons with Highest Categories:\")\n",
    "female_prisons = final_prison_df[(final_prison_df['Female'] == 1) & (final_prison_df['Male'] == 0)]\n",
    "sample_female = female_prisons.sample(min(5, len(female_prisons)))\n",
    "for _, row in sample_female.iterrows():\n",
    "    print(f\"  {row['Prison_name']}:\")\n",
    "    print(f\"    Original Categories: Female_open={row['Female_open']}, Female_closed={row['Female_closed']}\")\n",
    "    print(f\"    Highest Category: {row['Highest_category_female']}\")\n",
    "\n",
    "\n",
    "# Saving the output\n",
    "prison_df.to_csv('Output/Pre-processed_data/final_prison_data_2014_2024.csv', index=False)\n",
    "prison_df.to_excel('Output/Pre-processed_data/final_prison_data_2014_2024.xlsx', index=False)\n",
    "print(\"\\nDataset saved to 'Pre-processed_data/final_prison_data_2014_2024.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bda8e6",
   "metadata": {},
   "source": [
    "## Integration of prison information toghether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's assume the first dataframe is called df1 and has 'Prison Name' column\n",
    "# and the second dataframe is called df2 and has 'Prison_name' column\n",
    "\n",
    "# Extract the unique prison names from both dataframes\n",
    "df1_prisons = set(merged_data_df['Prison Name'])\n",
    "df2_prisons = set(final_prison_df['Prison_name'])\n",
    "\n",
    "# Find prisons that are in df1 but not in df2\n",
    "only_in_df1 = df1_prisons - df2_prisons\n",
    "\n",
    "# Find prisons that are in df2 but not in df1\n",
    "only_in_df2 = df2_prisons - df1_prisons\n",
    "\n",
    "# Print the results\n",
    "print(\"Prisons in first dataframe but not in second:\")\n",
    "for prison in sorted(only_in_df1):\n",
    "    print(f\"- {prison}\")\n",
    "    \n",
    "print(\"\\nPrisons in second dataframe but not in first:\")\n",
    "for prison in sorted(only_in_df2):\n",
    "    print(f\"- {prison}\")\n",
    "\n",
    "# If there are no differences, print a confirmation\n",
    "if not only_in_df1 and not only_in_df2:\n",
    "    print(\"All prison names match across both dataframes.\")\n",
    "    \n",
    "# Sometimes string differences can be due to whitespace or capitalization\n",
    "# Let's check for potential close matches\n",
    "if only_in_df1 or only_in_df2:\n",
    "    print(\"\\nChecking for potential close matches (ignoring case and whitespace)...\")\n",
    "    \n",
    "    # Normalize names for comparison\n",
    "    df1_normalized = {p.lower().strip() for p in df1_prisons}\n",
    "    df2_normalized = {p.lower().strip() for p in df2_prisons}\n",
    "    \n",
    "    # Find potential matches\n",
    "    all_normalized = list(df1_normalized) + list(df2_normalized)\n",
    "    potential_matches = {}\n",
    "    \n",
    "    for i, name1 in enumerate(all_normalized):\n",
    "        for name2 in all_normalized[i+1:]:\n",
    "            if name1 == name2:\n",
    "                continue\n",
    "            # Check if one is a substring of the other\n",
    "            if name1 in name2 or name2 in name1:\n",
    "                potential_matches.setdefault(name1, set()).add(name2)\n",
    "                potential_matches.setdefault(name2, set()).add(name1)\n",
    "    \n",
    "    # Print potential matches\n",
    "    if potential_matches:\n",
    "        print(\"\\nPotential similar names found:\")\n",
    "        for name, matches in potential_matches.items():\n",
    "            if name in df1_normalized and any(m in df2_normalized for m in matches):\n",
    "                print(f\"- '{name}' might match with: {', '.join([f\"'{m}'\" for m in matches if m in df2_normalized])}\")\n",
    "            elif name in df2_normalized and any(m in df1_normalized for m in matches):\n",
    "                print(f\"- '{name}' might match with: {', '.join([f\"'{m}'\" for m in matches if m in df1_normalized])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = merged_data_df\n",
    "\n",
    "# Assuming your first dataframe is called df1\n",
    "# Remove rows for Haslar and Morton Hall prisons\n",
    "prisons_to_remove = ['Haslar', 'Morton Hall']\n",
    "df1_filtered = df1[~df1['Prison Name'].isin(prisons_to_remove)]\n",
    "\n",
    "# Verify removal\n",
    "print(f\"Original dataset size: {len(df1)} rows\")\n",
    "print(f\"Filtered dataset size: {len(df1_filtered)} rows\")\n",
    "print(f\"Removed {len(df1) - len(df1_filtered)} rows\")\n",
    "\n",
    "# Check that the prisons were actually removed\n",
    "remaining_prisons = set(df1_filtered['Prison Name'])\n",
    "print(\"\\nConfirming prisons were removed:\")\n",
    "for prison in prisons_to_remove:\n",
    "    if prison in remaining_prisons:\n",
    "        print(f\"- Warning: {prison} is still in the dataset\")\n",
    "    else:\n",
    "        print(f\"- {prison} was successfully removed\")\n",
    "\n",
    "# Save the filtered dataset if needed\n",
    "# df1_filtered.to_csv('filtered_prison_data.csv', index=False)\n",
    "\n",
    "# Display sample of the filtered dataset\n",
    "print(\"\\nSample of filtered dataset:\")\n",
    "print(df1_filtered.head())\n",
    "\n",
    "merged_data = df1_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming dataframes are named merged_data_df and final_prison_df\n",
    "# First, let's preprocess the date formats for comparison\n",
    "\n",
    "# Function to convert date strings to datetime objects\n",
    "def convert_period_to_date(period_str):\n",
    "    # Convert formats like \"10-2014\" to datetime objects\n",
    "    month, year = map(int, period_str.split('-'))\n",
    "    return datetime(year, month, 1)\n",
    "\n",
    "# Create datetime objects from Report_Date in merged_data\n",
    "merged_data_df['Report_Date'] = pd.to_datetime(merged_data_df['Report_Date'])\n",
    "\n",
    "# Create datetime objects from start_period and end_period in final_prison_df\n",
    "final_prison_df['start_date'] = final_prison_df['start_period'].apply(convert_period_to_date)\n",
    "final_prison_df['end_date'] = final_prison_df['end_period'].apply(convert_period_to_date)\n",
    "\n",
    "# Create a function to merge the datasets\n",
    "def merge_prison_data(left_df, right_df):\n",
    "    # Initialize an empty list to store matching rows\n",
    "    merged_rows = []\n",
    "    \n",
    "    # Iterate through each row in the left dataframe\n",
    "    for _, left_row in left_df.iterrows():\n",
    "        prison_name = left_row['Prison Name']\n",
    "        report_date = left_row['Report_Date']\n",
    "        \n",
    "        # Find matching prison names in the right dataframe\n",
    "        matching_prisons = right_df[right_df['Prison_name'] == prison_name]\n",
    "        \n",
    "        # Check if the report date falls within any of the matching prison's periods\n",
    "        for _, right_row in matching_prisons.iterrows():\n",
    "            if right_row['start_date'] <= report_date <= right_row['end_date']:\n",
    "                # Create a combined row with data from both dataframes\n",
    "                combined_row = pd.concat([left_row, right_row])\n",
    "                merged_rows.append(combined_row)\n",
    "                break  # Only take the first match per prison and date\n",
    "    \n",
    "    # Convert the list of rows into a dataframe\n",
    "    if merged_rows:\n",
    "        return pd.DataFrame(merged_rows)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Perform the merge\n",
    "result = merge_prison_data(merged_data_df, final_prison_df)\n",
    "\n",
    "# Clean up the result (remove duplicated columns if needed)\n",
    "# If 'Prison Name' and 'Prison_name' are duplicates, keep one\n",
    "if 'Prison Name' in result.columns and 'Prison_name' in result.columns:\n",
    "    result = result.drop(columns=['Prison_name'])\n",
    "\n",
    "# Print merge statistics\n",
    "print(f\"Original left dataframe size: {len(merged_data)} rows\")\n",
    "print(f\"Original right dataframe size: {len(final_prison_df)} rows\")\n",
    "print(f\"Merged dataframe size: {len(result)} rows\")\n",
    "print(f\"Rows dropped: {len(merged_data) - len(result)} rows\")\n",
    "\n",
    "# Display the first few rows of the merged result\n",
    "print(\"\\nMerged data preview:\")\n",
    "print(result.head())\n",
    "\n",
    "# Save the result\n",
    "result.to_csv('Output/Pre-processed_data/merged_prison_data_by_month.csv', index=False)\n",
    "result.to_excel('Output/Pre-processed_data/merged_prison_data_by_month.xlsx', index=False)\n",
    "\n",
    "result_copy = result.copy() #saving for later, for analysis needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df34b912",
   "metadata": {},
   "source": [
    "## Aggregating data across a given period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify period of interest\n",
    "start_date = pd.to_datetime('2014-10-01')\n",
    "end_date = pd.to_datetime('2024-09-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64720b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert Report_Date to datetime\n",
    "merged_data['Report_Date'] = pd.to_datetime(merged_data['Report_Date'])\n",
    "\n",
    "\n",
    "filtered_data = merged_data[(merged_data['Report_Date'] >= start_date) & \n",
    "                           (merged_data['Report_Date'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470aa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the filtered data\n",
    "prison_agg = (\n",
    "    filtered_data\n",
    "    .groupby(\"Prison Name\")\n",
    "    .agg(\n",
    "        Avg_Population=(\"Population *\", \"mean\"),\n",
    "        Avg_Occupancy_Percentage=(\"Occupancy_Percentage\", \"mean\"),\n",
    "        Avg_Deaths=(\"Total_Deaths\", \"mean\"),\n",
    "        Avg_Homicide=(\"Homicide\", \"mean\"),\n",
    "        Avg_SelfInflicted=(\"Self-Inflicted\", \"mean\"),\n",
    "        Avg_Natural=(\"Natural Causes\", \"mean\"),\n",
    "        Avg_Other=(\"Other\", \"mean\"),\n",
    "        N_Months=(\"Total_Deaths\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a97163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean up the result dataframe column names\n",
    "result.columns = [col.replace('*', '').strip() for col in result.columns]\n",
    "\n",
    "# Convert end_period to datetime for sorting\n",
    "result['end_period'] = pd.to_datetime(result['end_period'], errors='coerce')\n",
    "\n",
    "# Sort the result dataframe by prison name and end_period\n",
    "result_sorted = result.sort_values(['Prison Name', 'end_period'])\n",
    "\n",
    "# Keep only the latest observation for each prison\n",
    "result_latest = result_sorted.drop_duplicates('Prison Name', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c766435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the aggregated data with the latest prison information\n",
    "final_dataset = pd.merge(\n",
    "    prison_agg,\n",
    "    result_latest,\n",
    "    left_on=\"Prison Name\",\n",
    "    right_on=\"Prison Name\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "# Rename the column 'Prison Name' to 'Prison_name' in the final_dataset dataframe\n",
    "final_dataset.rename(columns={'Prison Name': 'Prison_name'}, inplace=True)\n",
    "\n",
    "\n",
    "# Keep only the columns we need\n",
    "keep_columns = [\n",
    "    'Prison_name',           # Prison identifier\n",
    "    'Avg_Population',        # Average metrics from merged_data\n",
    "    'Avg_Occupancy_Percentage',\n",
    "    'Avg_Deaths',\n",
    "    'Avg_Homicide',\n",
    "    'Avg_SelfInflicted',\n",
    "    'Avg_Natural',\n",
    "    'Avg_Other',\n",
    "    'N_Months',\n",
    "    'A', 'B', 'C', 'D',      # Prison type indicators\n",
    "    'YOI',\n",
    "    'Male', 'Female', \n",
    "    'Mixed',\n",
    "    'Female_open', \n",
    "    'Female_closed',\n",
    "    'Highest_category_male',\n",
    "    'Highest_category_female'\n",
    "]\n",
    "\n",
    "final_clean = final_dataset[keep_columns]\n",
    "\n",
    "# Display summary info\n",
    "print(f\"Final dataset has {final_clean.shape[0]} prisons and {final_clean.shape[1]} columns\")\n",
    "\n",
    "final_clean.to_excel('Output/Pre-processed_data/prison_agg_data_2014_2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c34ca",
   "metadata": {},
   "source": [
    "## Generate weighted aggregated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted = merged_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Drop rows with missing Overcrowding_Status\n",
    "df_weighted = df_weighted.dropna(subset=['Overcrowding_Status'])\n",
    "\n",
    "# Step 2: Create Month-Year column from Report_Date\n",
    "df_weighted['Report_Date'] = pd.to_datetime(df_weighted['Report_Date'])  # Ensure datetime dtype\n",
    "df_weighted['Month_Year'] = df_weighted['Report_Date'].dt.to_period('M')\n",
    "\n",
    "# Step 3: Flag COVID-period data\n",
    "df_weighted['Is_covid_acute'] = df_weighted['Report_Date'].between('2020-03-01', '2020-09-15').astype(int)\n",
    "df_weighted['Is_covid_residual'] = df_weighted['Report_Date'].between('2020-09-16', '2021-06-15').astype(int)\n",
    "df_weighted['Is_covid_ending'] = df_weighted['Report_Date'].between('2021-06-16', '2022-03-31').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330506d3",
   "metadata": {},
   "source": [
    "Estimating the effect of COVID-19 pandamic on excess mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e6570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_estimating_equations import GEE\n",
    "from statsmodels.genmod.families import Poisson\n",
    "from statsmodels.genmod.cov_struct import Autoregressive\n",
    "\n",
    "model = GEE.from_formula(\n",
    "    \"Total_Deaths ~ Is_covid_acute + Is_covid_residual + Is_covid_ending\",\n",
    "    groups=\"Prison Name\",\n",
    "    cov_struct=Autoregressive(),\n",
    "    family=Poisson(),\n",
    "    data=df_weighted\n",
    ")\n",
    "result = model.fit()\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18811db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating weight columns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Make sure Report_Date is datetime\n",
    "df_weighted['Report_Date'] = pd.to_datetime(df_weighted['Report_Date'])\n",
    "\n",
    "# Reference point for weighting – latest date in dataset (can be overridden)\n",
    "latest_date = df_weighted['Report_Date'].max()\n",
    "\n",
    "# Step 4: Compute recency in months (how far from the latest date)\n",
    "df_weighted['Months_Since'] = ((latest_date - df_weighted['Report_Date']) / pd.Timedelta(days=30)).round().astype(int)\n",
    "\n",
    "# Step 5: Define linear weight (more recent = higher weight)\n",
    "max_months = df_weighted['Months_Since'].max()\n",
    "df_weighted['Time_Weight_Linear'] = 1 - (df_weighted['Months_Since'] / max_months)\n",
    "\n",
    "# Optional: Clip to ensure non-negative\n",
    "df_weighted['Time_Weight_Linear'] = df_weighted['Time_Weight_Linear'].clip(lower=0.01)\n",
    "\n",
    "# ---- Optional: Exponential decay (steeper discount) ----\n",
    "decay_rate = 0.05  # change this value to control steepness\n",
    "df_weighted['Time_Weight_Exp'] = np.exp(-decay_rate * df_weighted['Months_Since'])\n",
    "\n",
    "# Preview\n",
    "print(df_weighted[['Report_Date', 'Months_Since', 'Time_Weight_Linear', 'Time_Weight_Exp']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining penalty multipliers for each COVID phase based on the results of the excess deaths estimation\n",
    "acute_penalty = 1          # Acute phase: 100% weight\n",
    "residual_penalty = 0.74      # Residual phase: 74% weight\n",
    "ending_penalty = 1         # Ending phase: 100% weight\n",
    "\n",
    "# Create COVID adjustment factor (weighted mask)\n",
    "df_weighted['Covid_Adjustment'] = (\n",
    "    df_weighted['Is_covid_acute'] * acute_penalty +\n",
    "    df_weighted['Is_covid_residual'] * residual_penalty +\n",
    "    df_weighted['Is_covid_ending'] * ending_penalty +\n",
    "    (~(\n",
    "        df_weighted['Is_covid_acute'].astype(bool) |\n",
    "        df_weighted['Is_covid_residual'].astype(bool) |\n",
    "        df_weighted['Is_covid_ending'].astype(bool)\n",
    "     )).astype(float) * 1.0  # non-COVID gets full weight\n",
    ")\n",
    "\n",
    "# Apply COVID adjustment to both weight types\n",
    "df_weighted['Weight_Linear_Covid'] = df_weighted['Time_Weight_Linear'] * df_weighted['Covid_Adjustment']\n",
    "df_weighted['Weight_Exp_Covid'] = df_weighted['Time_Weight_Exp'] * df_weighted['Covid_Adjustment']\n",
    "\n",
    "# Optional: prevent too-small weights\n",
    "df_weighted['Weight_Linear_Covid'] = df_weighted['Weight_Linear_Covid'].clip(lower=0.01)\n",
    "df_weighted['Weight_Exp_Covid'] = df_weighted['Weight_Exp_Covid'].clip(lower=0.01)\n",
    "\n",
    "# Preview\n",
    "print(df_weighted[['Report_Date', 'Months_Since', 'Covid_Adjustment',\n",
    "                   'Time_Weight_Linear', 'Time_Weight_Exp',\n",
    "                   'Weight_Linear_Covid', 'Weight_Exp_Covid']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcebe32",
   "metadata": {},
   "source": [
    "Adding weights based on prison population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32089d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: rename population column if needed\n",
    "df_weighted = df_weighted.rename(columns={'Population *': 'Population'})\n",
    "\n",
    "# --- Add weights with population adjustment ---\n",
    "df_weighted['Weight_Linear_Covid_Pop'] = df_weighted['Weight_Linear_Covid'] * df_weighted['Population']\n",
    "df_weighted['Weight_Exp_Covid_Pop'] = df_weighted['Weight_Exp_Covid'] * df_weighted['Population']\n",
    "\n",
    "# Optional: ensure no zero or negative weights (if population has zeros, though unlikely)\n",
    "df_weighted['Weight_Linear_Covid_Pop'] = df_weighted['Weight_Linear_Covid_Pop'].clip(lower=0.01)\n",
    "df_weighted['Weight_Exp_Covid_Pop'] = df_weighted['Weight_Exp_Covid_Pop'].clip(lower=0.01)\n",
    "\n",
    "# Show a random sample of 10 observations to inspect weight variability\n",
    "print(df_weighted[['Report_Date', 'Population', 'Months_Since', 'Covid_Adjustment',\n",
    "                   'Time_Weight_Linear', 'Time_Weight_Exp',\n",
    "                   'Weight_Linear_Covid', 'Weight_Exp_Covid',\n",
    "                   'Weight_Linear_Covid_Pop', 'Weight_Exp_Covid_Pop']].sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49420855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the result\n",
    "df_weighted.to_excel('Output/For_analysis/merged_data_monthly_2014_2024_weighted.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the six weighting columns\n",
    "weight_columns = {\n",
    "    \"linear\": \"Time_Weight_Linear\",\n",
    "    \"exp\": \"Time_Weight_Exp\",\n",
    "    \"linear_covid\": \"Weight_Linear_Covid\",\n",
    "    \"exp_covid\": \"Weight_Exp_Covid\",\n",
    "    \"linear_covid_pop\": \"Weight_Linear_Covid_Pop\",\n",
    "    \"exp_covid_pop\": \"Weight_Exp_Covid_Pop\"\n",
    "}\n",
    "\n",
    "# Target columns for weighted aggregation\n",
    "agg_targets = {\n",
    "    \"Population\": \"Avg_Population\",\n",
    "    \"Occupancy_Percentage\": \"Avg_Occupancy_Percentage\",\n",
    "    \"Total_Deaths\": \"Avg_Deaths\",\n",
    "    \"Homicide\": \"Avg_Homicide\",\n",
    "    \"Self-Inflicted\": \"Avg_SelfInflicted\",\n",
    "    \"Natural Causes\": \"Avg_Natural\",\n",
    "    \"Other\": \"Avg_Other\"\n",
    "}\n",
    "\n",
    "# Extra attributes to merge in (last known info per prison)\n",
    "extra_cols = [\n",
    "    'A', 'B', 'C', 'D', 'YOI',\n",
    "    'Male', 'Female', 'Mixed',\n",
    "    'Female_open', 'Female_closed',\n",
    "    'Highest_category_male', 'Highest_category_female',\n",
    "    'end_period'\n",
    "]\n",
    "\n",
    "# Container for outputs\n",
    "agg_datasets = {}\n",
    "\n",
    "for key, weight_col in weight_columns.items():\n",
    "    df_temp = df_weighted.copy()\n",
    "    df_temp[\"weight\"] = df_temp[weight_col]\n",
    "\n",
    "    # Apply weights to each outcome\n",
    "    for col in agg_targets:\n",
    "        df_temp[f\"{col}_weighted\"] = df_temp[col] * df_temp[\"weight\"]\n",
    "\n",
    "    # Group by prison and calculate weighted sums and total weights\n",
    "    grouped = df_temp.groupby(\"Prison Name\").agg(\n",
    "        **{out_col: (f\"{in_col}_weighted\", \"sum\") for in_col, out_col in agg_targets.items()},\n",
    "        weight_sum=(\"weight\", \"sum\"),\n",
    "        N_Months=(\"Total_Deaths\", \"count\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute weighted means\n",
    "    for out_col in agg_targets.values():\n",
    "        grouped[out_col] = grouped[out_col] / grouped[\"weight_sum\"]\n",
    "\n",
    "    # Get the latest info per prison for non-aggregated columns\n",
    "    latest_info = (\n",
    "        df_temp.sort_values(['Prison Name', 'end_period'])\n",
    "        .drop_duplicates('Prison Name', keep='last')\n",
    "        [['Prison Name'] + extra_cols]\n",
    "    )\n",
    "\n",
    "    # Merge the metadata\n",
    "    merged = pd.merge(grouped, latest_info, on=\"Prison Name\", how=\"left\")\n",
    "    merged.rename(columns={'Prison Name': 'Prison_name'}, inplace=True)\n",
    "\n",
    "    # Reorder and trim to match original structure\n",
    "    final_columns = [\n",
    "        'Prison_name',\n",
    "        'Avg_Population', 'Avg_Occupancy_Percentage',\n",
    "        'Avg_Deaths', 'Avg_Homicide', 'Avg_SelfInflicted',\n",
    "        'Avg_Natural', 'Avg_Other', 'N_Months'\n",
    "    ] + extra_cols[:-1] #+ ['Highest_category_male', 'Highest_category_female']\n",
    "\n",
    "    agg_datasets[key] = merged[final_columns]\n",
    "\n",
    "    # Optionally save to Excel\n",
    "    output_path = f\"Output/For_analysis/prison_agg_2014_2024_weighted_{key}.xlsx\"\n",
    "    merged[final_columns].to_excel(output_path, index=False)\n",
    "\n",
    "print(\"All 6 weighted aggregate datasets prepared and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1f10a",
   "metadata": {},
   "source": [
    "# Prepare the folder for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clean.to_excel('Output/For_analysis/prison_agg_data_2014_2024.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c91b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where Overcrowding_Status is empty\n",
    "result_copy = result_copy.dropna(subset=['Overcrowding_Status'])\n",
    "result_copy.rename(columns={'Prison Name': 'Prison_name', 'Population *': 'Population'}, inplace=True)\n",
    "\n",
    "\n",
    "# Verify the change\n",
    "print(f\"Updated dataset size: {len(result_copy)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c611d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_copy.to_excel('Output/For_analysis/merged_data_monthly_2014_2024.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
